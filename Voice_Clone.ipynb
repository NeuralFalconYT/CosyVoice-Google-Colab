{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sq8oBdHQtyUZ"
      },
      "outputs": [],
      "source": [
        "#@title Install and Restart Session\n",
        "%cd /content/\n",
        "!rm -rf /content/whisperX\n",
        "!git clone https://github.com/m-bain/whisperX.git\n",
        "%cd /content/whisperX\n",
        "!pip install .\n",
        "!echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig\n",
        "!export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/lib\n",
        "!pip install srt\n",
        "!pip install deep_translator==1.11.4\n",
        "!pip install edge_tts==6.1.7\n",
        "!pip install gradio==4.19.2\n",
        "!pip install pydub==0.25.1\n",
        "!pip install pysrt==1.1.2\n",
        "!pip install librosa==0.10.2.post1\n",
        "!pip install yt-dlp==2024.2.16.232705.dev0\n",
        "!pip install ffmpeg==1.4\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "!pip install modelscope\n",
        "\n",
        "# root_path=\".\" #for windows/kaggle/mac\n",
        "# root_path=os.getcwd() #else use this one\n",
        "root_path=\"/content\" #if you are not running this on google colab comment this\n",
        "\n",
        "base_path=f\"{root_path}\"\n",
        "os.chdir(base_path)\n",
        "if os.path.exists(f\"{base_path}/CosyVoice\"):\n",
        "  shutil.rmtree(f\"{base_path}/CosyVoice\")\n",
        "  print(f\"Deleting Old {base_path}/CosyVoice\")\n",
        "!git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git\n",
        "os.chdir(f\"{base_path}/CosyVoice\")\n",
        "\n",
        "#Downloading Model using git clone is very slow\n",
        "# !git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M\n",
        "from modelscope import snapshot_download\n",
        "snapshot_download('iic/CosyVoice-300M', local_dir=f'{base_path}/CosyVoice/pretrained_models/CosyVoice-300M')\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "# !pip install matcha-tts\n",
        "# !echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig\n",
        "!pip install pydub==0.25.1\n",
        "!pip install pysrt==1.1.2\n",
        "!pip install librosa==0.10.2.post1\n",
        "\n",
        "%cd /content/\n",
        "!git clone https://github.com/shivammehta25/Matcha-TTS.git\n",
        "requirements = \"\"\"\n",
        "# --------- pytorch --------- #\n",
        "# torch>=2.0.0\n",
        "# torchvision>=0.15.0\n",
        "# lightning>=2.0.0\n",
        "# torchmetrics>=0.11.4\n",
        "\n",
        "# --------- hydra --------- #\n",
        "hydra-core==1.3.2\n",
        "hydra-colorlog==1.2.0\n",
        "hydra-optuna-sweeper==1.2.0\n",
        "\n",
        "# --------- loggers --------- #\n",
        "# wandb\n",
        "# neptune-client\n",
        "# mlflow\n",
        "# comet-ml\n",
        "# aim>=3.16.2  # no lower than 3.16.2, see https://github.com/aimhubio/aim/issues/2550\n",
        "\n",
        "# --------- others --------- #\n",
        "rootutils       # standardizing the project root setup\n",
        "pre-commit      # hooks for applying linters on commit\n",
        "rich            # beautiful text formatting in terminal\n",
        "pytest          # tests\n",
        "# sh            # for running bash commands in some tests (linux/macos only)\n",
        "phonemizer      # phonemization of text\n",
        "tensorboard\n",
        "librosa\n",
        "Cython\n",
        "numpy\n",
        "einops\n",
        "inflect\n",
        "Unidecode\n",
        "scipy\n",
        "# torchaudio\n",
        "matplotlib\n",
        "pandas\n",
        "conformer==0.3.2\n",
        "diffusers # developed using version ==0.25.0\n",
        "notebook\n",
        "ipywidgets\n",
        "# gradio==3.43.2\n",
        "gdown\n",
        "wget\n",
        "seaborn\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/Matcha-TTS/requirements.txt', 'w') as file:\n",
        "    file.write(requirements.strip())\n",
        "%cd /content/Matcha-TTS\n",
        "!pip install .\n",
        "%cd /content/\n",
        "!pip install whisperx==3.1.1\n",
        "!pip install gradio==4.36.1\n",
        "%cd /content\n",
        "!wget https://github.com/NeuralFalconYT/CosyVoice-Google-Colab/raw/main/temp.wav\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import time\n",
        "time.sleep(5)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dowload Model for the first time\n",
        "import whisperx\n",
        "import gc\n",
        "import torch\n",
        "from whisperx.alignment import (\n",
        "    DEFAULT_ALIGN_MODELS_TORCH as DAMT,\n",
        "    DEFAULT_ALIGN_MODELS_HF as DAMHF,\n",
        ")\n",
        "languages = {\n",
        "    \"None\": \"None\",\n",
        "    \"Afrikaans\": \"af\",\n",
        "    \"Amharic\": \"am\",\n",
        "    \"Arabic\": \"ar\",\n",
        "    \"Azerbaijani\": \"az\",\n",
        "    \"Bulgarian\": \"bg\",\n",
        "    \"Bengali\": \"bn\",\n",
        "    \"Bosnian\": \"bs\",\n",
        "    \"Catalan\": \"ca\",\n",
        "    \"Czech\": \"cs\",\n",
        "    \"Welsh\": \"cy\",\n",
        "    \"Danish\": \"da\",\n",
        "    \"German\": \"de\",\n",
        "    \"Greek\": \"el\",\n",
        "    \"English\": \"en\",\n",
        "    \"Spanish\": \"es\",\n",
        "    \"French\": \"fr\",\n",
        "    \"Irish\": \"ga\",\n",
        "    \"Galician\": \"gl\",\n",
        "    \"Gujarati\": \"gu\",\n",
        "    \"Hebrew\": \"he\",\n",
        "    \"Hindi\": \"hi\",\n",
        "    \"Croatian\": \"hr\",\n",
        "    \"Hungarian\": \"hu\",\n",
        "    \"Indonesian\": \"id\",\n",
        "    \"Icelandic\": \"is\",\n",
        "    \"Italian\": \"it\",\n",
        "    \"Japanese\": \"ja\",\n",
        "    \"Javanese\": \"jv\",\n",
        "    \"Georgian\": \"ka\",\n",
        "    \"Kazakh\": \"kk\",\n",
        "    \"Khmer\": \"km\",\n",
        "    \"Kannada\": \"kn\",\n",
        "    \"Korean\": \"ko\",\n",
        "    \"Lao\": \"lo\",\n",
        "    \"Lithuanian\": \"lt\",\n",
        "    \"Latvian\": \"lv\",\n",
        "    \"Macedonian\": \"mk\",\n",
        "    \"Malayalam\": \"ml\",\n",
        "    \"Mongolian\": \"mn\",\n",
        "    \"Marathi\": \"mr\",\n",
        "    \"Malay\": \"ms\",\n",
        "    \"Maltese\": \"mt\",\n",
        "    \"Burmese\": \"my\",\n",
        "    \"Norwegian Bokmål\": \"nb\",\n",
        "    \"Nepali\": \"ne\",\n",
        "    \"Dutch\": \"nl\",\n",
        "    \"Polish\": \"pl\",\n",
        "    \"Pashto\": \"ps\",\n",
        "    \"Portuguese\": \"pt\",\n",
        "    \"Romanian\": \"ro\",\n",
        "    \"Russian\": \"ru\",\n",
        "    \"Sinhala\": \"si\",\n",
        "    \"Slovak\": \"sk\",\n",
        "    \"Slovenian\": \"sl\",\n",
        "    \"Somali\": \"so\",\n",
        "    \"Albanian\": \"sq\",\n",
        "    \"Serbian\": \"sr\",\n",
        "    \"Sundanese\": \"su\",\n",
        "    \"Swedish\": \"sv\",\n",
        "    \"Swahili\": \"sw\",\n",
        "    \"Tamil\": \"ta\",\n",
        "    \"Telugu\": \"te\",\n",
        "    \"Thai\": \"th\",\n",
        "    \"Turkish\": \"tr\",\n",
        "    \"Ukrainian\": \"uk\",\n",
        "    \"Urdu\": \"ur\",\n",
        "    \"Uzbek\": \"uz\",\n",
        "    \"Vietnamese\": \"vi\",\n",
        "    \"Chinese\": \"zh\",\n",
        "    \"Zulu\": \"zu\"\n",
        "}\n",
        "\n",
        "LANGUAGES_UNIDIRECTIONAL = {\n",
        "    \"Aymara (ay)\": \"ay\",\n",
        "    \"Bambara (bm)\": \"bm\",\n",
        "    \"Cebuano (ceb)\": \"ceb\",\n",
        "    \"Chichewa (ny)\": \"ny\",\n",
        "    \"Divehi (dv)\": \"dv\",\n",
        "    \"Dogri (doi)\": \"doi\",\n",
        "    \"Ewe (ee)\": \"ee\",\n",
        "    \"Guarani (gn)\": \"gn\",\n",
        "    \"Iloko (ilo)\": \"ilo\",\n",
        "    \"Kinyarwanda (rw)\": \"rw\",\n",
        "    \"Krio (kri)\": \"kri\",\n",
        "    \"Kurdish (ku)\": \"ku\",\n",
        "    \"Kirghiz (ky)\": \"ky\",\n",
        "    \"Ganda (lg)\": \"lg\",\n",
        "    \"Maithili (mai)\": \"mai\",\n",
        "    \"Oriya (or)\": \"or\",\n",
        "    \"Oromo (om)\": \"om\",\n",
        "    \"Quechua (qu)\": \"qu\",\n",
        "    \"Samoan (sm)\": \"sm\",\n",
        "    \"Tigrinya (ti)\": \"ti\",\n",
        "    \"Tsonga (ts)\": \"ts\",\n",
        "    \"Akan (ak)\": \"ak\",\n",
        "    \"Uighur (ug)\": \"ug\"\n",
        "}\n",
        "LANGUAGES = {\n",
        "    \"Automatic detection\": \"Automatic detection\",\n",
        "    \"Arabic (ar)\": \"ar\",\n",
        "    \"Chinese - Simplified (zh-CN)\": \"zh\",\n",
        "    \"Czech (cs)\": \"cs\",\n",
        "    \"Danish (da)\": \"da\",\n",
        "    \"Dutch (nl)\": \"nl\",\n",
        "    \"English (en)\": \"en\",\n",
        "    \"Finnish (fi)\": \"fi\",\n",
        "    \"French (fr)\": \"fr\",\n",
        "    \"German (de)\": \"de\",\n",
        "    \"Greek (el)\": \"el\",\n",
        "    \"Hebrew (he)\": \"he\",\n",
        "    \"Hungarian (hu)\": \"hu\",\n",
        "    \"Italian (it)\": \"it\",\n",
        "    \"Japanese (ja)\": \"ja\",\n",
        "    \"Korean (ko)\": \"ko\",\n",
        "    \"Persian (fa)\": \"fa\",  # no aux gTTS\n",
        "    \"Polish (pl)\": \"pl\",\n",
        "    \"Portuguese (pt)\": \"pt\",\n",
        "    \"Russian (ru)\": \"ru\",\n",
        "    \"Spanish (es)\": \"es\",\n",
        "    \"Turkish (tr)\": \"tr\",\n",
        "    \"Ukrainian (uk)\": \"uk\",\n",
        "    \"Urdu (ur)\": \"ur\",\n",
        "    \"Vietnamese (vi)\": \"vi\",\n",
        "    \"Hindi (hi)\": \"hi\",\n",
        "    \"Indonesian (id)\": \"id\",\n",
        "    \"Bengali (bn)\": \"bn\",\n",
        "    \"Telugu (te)\": \"te\",\n",
        "    \"Marathi (mr)\": \"mr\",\n",
        "    \"Tamil (ta)\": \"ta\",\n",
        "    \"Javanese (jw|jv)\": \"jw\",\n",
        "    \"Catalan (ca)\": \"ca\",\n",
        "    \"Nepali (ne)\": \"ne\",\n",
        "    \"Thai (th)\": \"th\",\n",
        "    \"Swedish (sv)\": \"sv\",\n",
        "    \"Amharic (am)\": \"am\",\n",
        "    \"Welsh (cy)\": \"cy\",  # no aux gTTS\n",
        "    \"Estonian (et)\": \"et\",\n",
        "    \"Croatian (hr)\": \"hr\",\n",
        "    \"Icelandic (is)\": \"is\",\n",
        "    \"Georgian (ka)\": \"ka\",  # no aux gTTS\n",
        "    \"Khmer (km)\": \"km\",\n",
        "    \"Slovak (sk)\": \"sk\",\n",
        "    \"Albanian (sq)\": \"sq\",\n",
        "    \"Serbian (sr)\": \"sr\",\n",
        "    \"Azerbaijani (az)\": \"az\",  # no aux gTTS\n",
        "    \"Bulgarian (bg)\": \"bg\",\n",
        "    \"Galician (gl)\": \"gl\",  # no aux gTTS\n",
        "    \"Gujarati (gu)\": \"gu\",\n",
        "    \"Kazakh (kk)\": \"kk\",  # no aux gTTS\n",
        "    \"Kannada (kn)\": \"kn\",\n",
        "    \"Lithuanian (lt)\": \"lt\",  # no aux gTTS\n",
        "    \"Latvian (lv)\": \"lv\",\n",
        "    \"Macedonian (mk)\": \"mk\",  # no aux gTTS # error get align model\n",
        "    \"Malayalam (ml)\": \"ml\",\n",
        "    \"Malay (ms)\": \"ms\",  # error get align model\n",
        "    \"Romanian (ro)\": \"ro\",\n",
        "    \"Sinhala (si)\": \"si\",\n",
        "    \"Sundanese (su)\": \"su\",\n",
        "    \"Swahili (sw)\": \"sw\",  # error aling\n",
        "    \"Afrikaans (af)\": \"af\",\n",
        "    \"Bosnian (bs)\": \"bs\",\n",
        "    \"Latin (la)\": \"la\",\n",
        "    \"Myanmar Burmese (my)\": \"my\",\n",
        "    \"Norwegian (no|nb)\": \"no\",\n",
        "    \"Chinese - Traditional (zh-TW)\": \"zh-TW\",\n",
        "    \"Assamese (as)\": \"as\",\n",
        "    \"Basque (eu)\": \"eu\",\n",
        "    \"Hausa (ha)\": \"ha\",\n",
        "    \"Haitian Creole (ht)\": \"ht\",\n",
        "    \"Armenian (hy)\": \"hy\",\n",
        "    \"Lao (lo)\": \"lo\",\n",
        "    \"Malagasy (mg)\": \"mg\",\n",
        "    \"Mongolian (mn)\": \"mn\",\n",
        "    \"Maltese (mt)\": \"mt\",\n",
        "    \"Punjabi (pa)\": \"pa\",\n",
        "    \"Pashto (ps)\": \"ps\",\n",
        "    \"Slovenian (sl)\": \"sl\",\n",
        "    \"Shona (sn)\": \"sn\",\n",
        "    \"Somali (so)\": \"so\",\n",
        "    \"Tajik (tg)\": \"tg\",\n",
        "    \"Turkmen (tk)\": \"tk\",\n",
        "    \"Tatar (tt)\": \"tt\",\n",
        "    \"Uzbek (uz)\": \"uz\",\n",
        "    \"Yoruba (yo)\": \"yo\",\n",
        "    **LANGUAGES_UNIDIRECTIONAL\n",
        "}\n",
        "BASE_L_LIST = LANGUAGES.keys()\n",
        "LANGUAGES_LIST = [list(BASE_L_LIST)[0]] + sorted(list(BASE_L_LIST)[1:])\n",
        "EXTRA_ALIGN = {\n",
        "    \"id\": \"indonesian-nlp/wav2vec2-large-xlsr-indonesian\",\n",
        "    \"bn\": \"arijitx/wav2vec2-large-xlsr-bengali\",\n",
        "    \"mr\": \"sumedh/wav2vec2-large-xlsr-marathi\",\n",
        "    \"ta\": \"Amrrs/wav2vec2-large-xlsr-53-tamil\",\n",
        "    \"jw\": \"cahya/wav2vec2-large-xlsr-javanese\",\n",
        "    \"ne\": \"shniranjan/wav2vec2-large-xlsr-300m-nepali\",\n",
        "    \"th\": \"sakares/wav2vec2-large-xlsr-thai-demo\",\n",
        "    \"sv\": \"KBLab/wav2vec2-large-voxrex-swedish\",\n",
        "    \"am\": \"agkphysics/wav2vec2-large-xlsr-53-amharic\",\n",
        "    \"cy\": \"Srulikbdd/Wav2Vec2-large-xlsr-welsh\",\n",
        "    \"et\": \"anton-l/wav2vec2-large-xlsr-53-estonian\",\n",
        "    \"hr\": \"classla/wav2vec2-xls-r-parlaspeech-hr\",\n",
        "    \"is\": \"carlosdanielhernandezmena/wav2vec2-large-xlsr-53-icelandic-ep10-1000h\",\n",
        "    \"ka\": \"MehdiHosseiniMoghadam/wav2vec2-large-xlsr-53-Georgian\",\n",
        "    \"km\": \"vitouphy/wav2vec2-xls-r-300m-khmer\",\n",
        "    \"sk\": \"infinitejoy/wav2vec2-large-xls-r-300m-slovak\",\n",
        "    \"sq\": \"Alimzhan/wav2vec2-large-xls-r-300m-albanian-colab\",\n",
        "    \"sr\": \"dnikolic/wav2vec2-xlsr-530-serbian-colab\",\n",
        "    \"az\": \"nijatzeynalov/wav2vec2-large-mms-1b-azerbaijani-common_voice15.0\",\n",
        "    \"bg\": \"infinitejoy/wav2vec2-large-xls-r-300m-bulgarian\",\n",
        "    \"gl\": \"ifrz/wav2vec2-large-xlsr-galician\",\n",
        "    \"gu\": \"Harveenchadha/vakyansh-wav2vec2-gujarati-gnm-100\",\n",
        "    \"kk\": \"aismlv/wav2vec2-large-xlsr-kazakh\",\n",
        "    \"kn\": \"Harveenchadha/vakyansh-wav2vec2-kannada-knm-560\",\n",
        "    \"lt\": \"DeividasM/wav2vec2-large-xlsr-53-lithuanian\",\n",
        "    \"lv\": \"anton-l/wav2vec2-large-xlsr-53-latvian\",\n",
        "    \"mk\": \"\",  # Konstantin-Bogdanoski/wav2vec2-macedonian-base\n",
        "    \"ml\": \"gvs/wav2vec2-large-xlsr-malayalam\",\n",
        "    \"ms\": \"\",  # Duy/wav2vec2_malay\n",
        "    \"ro\": \"anton-l/wav2vec2-large-xlsr-53-romanian\",\n",
        "    \"si\": \"IAmNotAnanth/wav2vec2-large-xls-r-300m-sinhala\",\n",
        "    \"su\": \"cahya/wav2vec2-large-xlsr-sundanese\",\n",
        "    \"sw\": \"\",  # Lians/fine-tune-wav2vec2-large-swahili\n",
        "    \"af\": \"\",  # ylacombe/wav2vec2-common_voice-af-demo\n",
        "    \"bs\": \"\",\n",
        "    \"la\": \"\",\n",
        "    \"my\": \"\",\n",
        "    \"no\": \"NbAiLab/wav2vec2-xlsr-300m-norwegian\",\n",
        "    \"zh-TW\": \"jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn\",\n",
        "    \"as\": \"\",\n",
        "    \"eu\": \"\", # cahya/wav2vec2-large-xlsr-basque # verify\n",
        "    \"ha\": \"infinitejoy/wav2vec2-large-xls-r-300m-hausa\",\n",
        "    \"ht\": \"\",\n",
        "    \"hy\": \"infinitejoy/wav2vec2-large-xls-r-300m-armenian\", # no (.)\n",
        "    \"lo\": \"\",\n",
        "    \"mg\": \"\",\n",
        "    \"mn\": \"tugstugi/wav2vec2-large-xlsr-53-mongolian\",\n",
        "    \"mt\": \"carlosdanielhernandezmena/wav2vec2-large-xlsr-53-maltese-64h\",\n",
        "    \"pa\": \"kingabzpro/wav2vec2-large-xlsr-53-punjabi\",\n",
        "    \"ps\": \"aamirhs/wav2vec2-large-xls-r-300m-pashto-colab\",\n",
        "    \"sl\": \"anton-l/wav2vec2-large-xlsr-53-slovenian\",\n",
        "    \"sn\": \"\",\n",
        "    \"so\": \"\",\n",
        "    \"tg\": \"\",\n",
        "    \"tk\": \"\",  # Ragav/wav2vec2-tk\n",
        "    \"tt\": \"anton-l/wav2vec2-large-xlsr-53-tatar\",\n",
        "    \"uz\": \"\",  # Mekhriddin/wav2vec2-large-xls-r-300m-uzbek-colab\n",
        "    \"yo\": \"ogbi/wav2vec2-large-mms-1b-yoruba-test\",\n",
        "}\n",
        "\n",
        "\n",
        "INVERTED_LANGUAGES = {value: key for key, value in LANGUAGES.items()}\n",
        "TRANSLATION_PROCESS_OPTIONS = [\n",
        "    \"google_translator_batch\",\n",
        "    \"google_translator\",\n",
        "]\n",
        "\n",
        "def transcribe_speech(audio_path,language_name=None):\n",
        "  asr_options = {\n",
        "        \"initial_prompt\": None,\n",
        "        \"suppress_numerals\": True\n",
        "    }\n",
        "\n",
        "  whisperx_model = whisperx.load_model(\n",
        "        \"large-v3\",\n",
        "        \"cuda\" ,\n",
        "        compute_type=\"auto\",\n",
        "        language=language_name,\n",
        "        asr_options=asr_options,\n",
        "    )\n",
        "  audio = whisperx.load_audio(audio_path)\n",
        "  result = whisperx_model.transcribe(\n",
        "      audio,\n",
        "      batch_size=16,\n",
        "      chunk_size=15,\n",
        "      print_progress=True,\n",
        "  )\n",
        "  del whisperx_model\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()  # noqa\n",
        "  return audio, result\n",
        "\n",
        "def align_speech(audio, result):\n",
        "    \"\"\"\n",
        "    Aligns speech segments based on the provided audio and result metadata.\n",
        "\n",
        "    Parameters:\n",
        "    - audio (array): The audio data in a suitable format for alignment.\n",
        "    - result (dict): Metadata containing information about the segments\n",
        "         and language.\n",
        "\n",
        "    Returns:\n",
        "    - result (dict): Updated metadata after aligning the segments with\n",
        "        the audio. This includes character-level alignments if\n",
        "        'return_char_alignments' is set to True.\n",
        "\n",
        "    Notes:\n",
        "    - This function uses language-specific models to align speech segments.\n",
        "    - It performs language compatibility checks and selects the\n",
        "        appropriate alignment model.\n",
        "    - Cleans up memory by releasing resources after alignment.\n",
        "    \"\"\"\n",
        "    global LANGUAGES,EXTRA_ALIGN,INVERTED_LANGUAGES\n",
        "    my_lang= result[\"language\"]\n",
        "    DAMHF.update(DAMT)  # lang align\n",
        "    if (\n",
        "        not result[\"language\"] in DAMHF.keys()\n",
        "        and not result[\"language\"] in EXTRA_ALIGN.keys()\n",
        "    ):\n",
        "        print(\n",
        "            \"Automatic detection: Source language not compatible with align\"\n",
        "        )\n",
        "        # raise ValueError(\n",
        "        #     f\"Detected language {result['language']}  incompatible, \"\n",
        "        #     \"you can select the source language to avoid this error.\"\n",
        "        # )\n",
        "    if (\n",
        "        result[\"language\"] in EXTRA_ALIGN.keys()\n",
        "        and EXTRA_ALIGN[result[\"language\"]] == \"\"\n",
        "    ):\n",
        "        lang_name = (\n",
        "            INVERTED_LANGUAGES[result[\"language\"]]\n",
        "            if result[\"language\"] in INVERTED_LANGUAGES.keys()\n",
        "            else result[\"language\"]\n",
        "        )\n",
        "        # logger.warning(\n",
        "        #     \"No compatible wav2vec2 model found \"\n",
        "        #     f\"for the language '{lang_name}', skipping alignment.\"\n",
        "        # )\n",
        "        return result\n",
        "\n",
        "    model_a, metadata = whisperx.load_align_model(\n",
        "        language_code=result[\"language\"],\n",
        "        device=\"cuda\",\n",
        "        model_name=None\n",
        "        if result[\"language\"] in DAMHF.keys()\n",
        "        else EXTRA_ALIGN[result[\"language\"]],\n",
        "    )\n",
        "    result = whisperx.align(\n",
        "        result[\"segments\"],\n",
        "        model_a,\n",
        "        metadata,\n",
        "        audio,\n",
        "        \"cuda\",\n",
        "        return_char_alignments=True,\n",
        "        print_progress=False,\n",
        "    )\n",
        "    del model_a\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()  # noqa\n",
        "    return result,my_lang\n",
        "\n",
        "\n",
        "def linguistic_level_segments(\n",
        "    result_base,\n",
        "    linguistic_unit=\"word\",  # word or char\n",
        "):\n",
        "    linguistic_unit = linguistic_unit[:4]\n",
        "    linguistic_unit_key = linguistic_unit + \"s\"\n",
        "    result = copy.deepcopy(result_base)\n",
        "\n",
        "    if linguistic_unit_key not in result[\"segments\"][0].keys():\n",
        "        raise ValueError(\"No alignment detected, can't process\")\n",
        "\n",
        "    segments_by_unit = []\n",
        "    for segment in result[\"segments\"]:\n",
        "        segment_units = segment[linguistic_unit_key]\n",
        "        # segment_speaker = segment.get(\"speaker\", \"SPEAKER_00\")\n",
        "\n",
        "        for unit in segment_units:\n",
        "\n",
        "            text = unit[linguistic_unit]\n",
        "\n",
        "            if \"start\" in unit.keys():\n",
        "                segments_by_unit.append(\n",
        "                    {\n",
        "                        \"start\": unit[\"start\"],\n",
        "                        \"end\": unit[\"end\"],\n",
        "                        \"text\": text,\n",
        "                        # \"speaker\": segment_speaker,\n",
        "                    }\n",
        "                    )\n",
        "            elif not segments_by_unit:\n",
        "                pass\n",
        "            else:\n",
        "                segments_by_unit[-1][\"text\"] += text\n",
        "\n",
        "    return {\"segments\": segments_by_unit}\n",
        "\n",
        "from whisperx.utils import get_writer\n",
        "import os\n",
        "import copy\n",
        "import os\n",
        "\n",
        "def extract_folder_and_filename(file_path):\n",
        "    folder_path = os.path.dirname(file_path)\n",
        "    filename_with_ext = os.path.basename(file_path)\n",
        "    filename_without_ext = os.path.splitext(filename_with_ext)[0]\n",
        "    return folder_path, filename_without_ext+\".\"\n",
        "\n",
        "\n",
        "def process_subtitles(result,srt_full_path=\"\"):\n",
        "  subs_copy_result = copy.deepcopy(result)\n",
        "  for segment in subs_copy_result[\"segments\"]:\n",
        "      segment.pop(\"speaker\", None)\n",
        "  save_folder, name_ori = extract_folder_and_filename(srt_full_path)\n",
        "  writer = get_writer(\"srt\", output_dir=save_folder)\n",
        "  word_options = {\n",
        "      \"highlight_words\": False,\n",
        "      \"max_line_count\": None,\n",
        "      \"max_line_width\": None,\n",
        "  }\n",
        "  try:\n",
        "    writer(\n",
        "      subs_copy_result,\n",
        "      name_ori[:-1] + \".mp3\",\n",
        "      word_options,\n",
        "      )\n",
        "  except:\n",
        "    subs_copy_result[\"segments\"][0].pop(\"words\")\n",
        "    writer(\n",
        "              subs_copy_result,\n",
        "              name_ori[:-1] + \".mp3\",\n",
        "              word_options,\n",
        "          )\n",
        "  return f\"{save_folder}/{name_ori}srt\"\n",
        "\n",
        "\n",
        "def whisper_subtitle_generator(audio_path,Source_Language,Destination_Language):\n",
        "  _,temp_name=extract_folder_and_filename(audio_path)\n",
        "  temp_name=temp_name[:-1]\n",
        "  if not os.path.exists(\"/content/subtitle/\"):\n",
        "    os.makedirs(\"/content/subtitle/\")\n",
        "  original_srt=f\"/content/subtitle/Original_{Source_Language}_{temp_name}.srt\"\n",
        "  original_word_level_srt=f\"/content/subtitle/Original_{Source_Language}_world_level_{temp_name}.srt\"\n",
        "  translated_srt=f\"/content/subtitle/Translated_{Destination_Language}_{temp_name}.srt\"\n",
        "  if Source_Language==\"None\":\n",
        "    audio, result=transcribe_speech(audio_path,None)\n",
        "  else:\n",
        "    audio, result=transcribe_speech(audio_path,Source_Language)\n",
        "  result,get_lang=align_speech(audio, result)\n",
        "  original_result = copy.deepcopy(result)\n",
        "  process_subtitles(original_result,original_srt)\n",
        "  wordl_level_result=linguistic_level_segments(result,linguistic_unit=\"word\")\n",
        "  process_subtitles(wordl_level_result,original_word_level_srt)\n",
        "  Source_Language=get_lang\n",
        "  if Source_Language==Destination_Language:\n",
        "    return original_srt,original_word_level_srt,original_srt\n",
        "  else:\n",
        "    original_result = copy.deepcopy(result)\n",
        "    translate_res=translate_whisper_text(result,Source_Language,Destination_Language)\n",
        "    process_subtitles(translate_res,translated_srt)\n",
        "    return original_srt,original_word_level_srt,translated_srt\n",
        "\n",
        "\n",
        "import shutil\n",
        "import re\n",
        "import uuid\n",
        "def clean_file_name(file_path):\n",
        "  # Get the base file name and extension\n",
        "  file_name = os.path.basename(file_path)\n",
        "  file_name, file_extension = os.path.splitext(file_name)\n",
        "  cleaned = re.sub(r'[^a-zA-Z\\d]+', '_', file_name)   # Replace non-alphabetic characters with single underscore\n",
        "  clean_file_name=re.sub(r'([a-zA-Z])_+([a-zA-Z])', r'\\1_\\2', cleaned)  # Replace multiple underscores between alphabets with one underscore\n",
        "  clean_file_name = clean_file_name.strip('_')\n",
        "  random_uuid = uuid.uuid4().hex[:6]\n",
        "  # Combine cleaned file name with the original extension\n",
        "  clean_file_path = os.path.join(os.path.dirname(file_path), clean_file_name +f\"_{random_uuid}\"+file_extension)\n",
        "  return clean_file_path\n",
        "def gradio_whisper_subtitle(gradio_file_path,Source_Language,Destination_Language):\n",
        "  global languages\n",
        "  audio_file_path=os.path.basename(gradio_file_path)\n",
        "  audio_file_path=f\"/content/gradio_upload/{audio_file_path}\"\n",
        "  audio_file_path=clean_file_name(audio_file_path)\n",
        "  if not os.path.exists(\"/content/gradio_upload\"):\n",
        "    os.mkdir(\"/content/gradio_upload\")\n",
        "  shutil.copy(gradio_file_path,audio_file_path)\n",
        "\n",
        "  if audio_file_path.lower().endswith(\".mp4\"):\n",
        "    file_name = os.path.splitext(os.path.basename(audio_file_path))[0]\n",
        "    temp_path=f\"/content/gradio_upload/{file_name}.mp3\"\n",
        "    command=f\"ffmpeg -i {audio_file_path} {temp_path}\"\n",
        "    var=os.system(command)\n",
        "    if var==0:\n",
        "      audio_path=temp_path\n",
        "    else:\n",
        "      print(\"Failed\")\n",
        "      print(command)\n",
        "  else:\n",
        "    audio_path=audio_file_path\n",
        "  original_srt,original_word_level_srt,translated_srt=whisper_subtitle_generator(audio_path,languages[Source_Language],languages[Destination_Language])\n",
        "  return original_srt,original_word_level_srt,translated_srt,\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "\n",
        "#@title translate\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "import copy\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def translate_iterative(segments, target, source=None):\n",
        "    \"\"\"\n",
        "    Translate text segments individually to the specified language.\n",
        "\n",
        "    Parameters:\n",
        "    - segments (list): A list of dictionaries with 'text' as a key for\n",
        "        segment text.\n",
        "    - target (str): Target language code.\n",
        "    - source (str, optional): Source language code. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "    - list: Translated text segments in the target language.\n",
        "\n",
        "    Notes:\n",
        "    - Translates each segment using Google Translate.\n",
        "\n",
        "    Example:\n",
        "    segments = [{'text': 'first segment.'}, {'text': 'second segment.'}]\n",
        "    translated_segments = translate_iterative(segments, 'es')\n",
        "    \"\"\"\n",
        "\n",
        "    segments_ = copy.deepcopy(segments)\n",
        "\n",
        "    if (\n",
        "        not source\n",
        "    ):\n",
        "        print(\"No source language\")\n",
        "        source = \"auto\"\n",
        "\n",
        "    translator = GoogleTranslator(source=source, target=target)\n",
        "    for line in tqdm(range(len(segments_))):\n",
        "        text = segments_[line][\"text\"]\n",
        "        translated_line = translator.translate(text.strip())\n",
        "        segments_[line][\"text\"] = translated_line\n",
        "\n",
        "    return segments_\n",
        "\n",
        "\n",
        "def verify_translate(\n",
        "    segments,\n",
        "    segments_copy,\n",
        "    translated_lines,\n",
        "    target,\n",
        "    source\n",
        "):\n",
        "    \"\"\"\n",
        "    Verify integrity and translate segments if lengths match, otherwise\n",
        "    switch to iterative translation.\n",
        "    \"\"\"\n",
        "    if len(segments) == len(translated_lines):\n",
        "        for line in range(len(segments_copy)):\n",
        "            print(\n",
        "                f\"{segments_copy[line]['text']} >> \"\n",
        "                f\"{translated_lines[line].strip()}\"\n",
        "            )\n",
        "            segments_copy[line][\"text\"] = translated_lines[\n",
        "                line].replace(\"\\t\", \"\").replace(\"\\n\", \"\").strip()\n",
        "        return segments_copy\n",
        "    else:\n",
        "        print(\n",
        "            \"The translation failed, switching to google_translate iterative. \"\n",
        "            f\"{len(segments), len(translated_lines)}\"\n",
        "        )\n",
        "        return translate_iterative(segments, target, source)\n",
        "\n",
        "\n",
        "def translate_batch(segments, target, chunk_size=2000, source=None):\n",
        "    \"\"\"\n",
        "    Translate a batch of text segments into the specified language in chunks,\n",
        "        respecting the character limit.\n",
        "\n",
        "    Parameters:\n",
        "    - segments (list): List of dictionaries with 'text' as a key for segment\n",
        "        text.\n",
        "    - target (str): Target language code.\n",
        "    - chunk_size (int, optional): Maximum character limit for each translation\n",
        "        chunk (default is 2000; max 5000).\n",
        "    - source (str, optional): Source language code. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "    - list: Translated text segments in the target language.\n",
        "\n",
        "    Notes:\n",
        "    - Splits input segments into chunks respecting the character limit for\n",
        "        translation.\n",
        "    - Translates the chunks using Google Translate.\n",
        "    - If chunked translation fails, switches to iterative translation using\n",
        "        `translate_iterative()`.\n",
        "\n",
        "    Example:\n",
        "    segments = [{'text': 'first segment.'}, {'text': 'second segment.'}]\n",
        "    translated = translate_batch(segments, 'es', chunk_size=4000, source='en')\n",
        "    \"\"\"\n",
        "\n",
        "    segments_copy = copy.deepcopy(segments)\n",
        "\n",
        "    if (\n",
        "        not source\n",
        "    ):\n",
        "        print(\"No source language\")\n",
        "        source = \"auto\"\n",
        "\n",
        "    # Get text\n",
        "    text_lines = []\n",
        "    for line in range(len(segments_copy)):\n",
        "        text = segments_copy[line][\"text\"].strip()\n",
        "        text_lines.append(text)\n",
        "\n",
        "    # chunk limit\n",
        "    text_merge = []\n",
        "    actual_chunk = \"\"\n",
        "    global_text_list = []\n",
        "    actual_text_list = []\n",
        "    for one_line in text_lines:\n",
        "        one_line = \" \" if not one_line else one_line\n",
        "        if (len(actual_chunk) + len(one_line)) <= chunk_size:\n",
        "            if actual_chunk:\n",
        "                actual_chunk += \" ||||| \"\n",
        "            actual_chunk += one_line\n",
        "            actual_text_list.append(one_line)\n",
        "        else:\n",
        "            text_merge.append(actual_chunk)\n",
        "            actual_chunk = one_line\n",
        "            global_text_list.append(actual_text_list)\n",
        "            actual_text_list = [one_line]\n",
        "    if actual_chunk:\n",
        "        text_merge.append(actual_chunk)\n",
        "        global_text_list.append(actual_text_list)\n",
        "\n",
        "    # translate chunks\n",
        "    progress_bar = tqdm(total=len(segments), desc=\"Translating\")\n",
        "    translator = GoogleTranslator(source=source, target=target)\n",
        "    split_list = []\n",
        "    try:\n",
        "        for text, text_iterable in zip(text_merge, global_text_list):\n",
        "            translated_line = translator.translate(text.strip())\n",
        "            split_text = translated_line.split(\"|||||\")\n",
        "            if len(split_text) == len(text_iterable):\n",
        "                progress_bar.update(len(split_text))\n",
        "            else:\n",
        "                print(\n",
        "                    \"Chunk fixing iteratively. Len chunk: \"\n",
        "                    f\"{len(split_text)}, expected: {len(text_iterable)}\"\n",
        "                )\n",
        "                split_text = []\n",
        "                for txt_iter in text_iterable:\n",
        "                    translated_txt = translator.translate(txt_iter.strip())\n",
        "                    split_text.append(translated_txt)\n",
        "                    progress_bar.update(1)\n",
        "            split_list.append(split_text)\n",
        "        progress_bar.close()\n",
        "    except Exception as error:\n",
        "        progress_bar.close()\n",
        "        print(str(error))\n",
        "        print(\n",
        "            \"The translation in chunks failed, switching to iterative.\"\n",
        "            \" Related: too many request\"\n",
        "        )  # use proxy or less chunk size\n",
        "        return translate_iterative(segments, target, source)\n",
        "\n",
        "    # un chunk\n",
        "    translated_lines = list(chain.from_iterable(split_list))\n",
        "\n",
        "    return verify_translate(\n",
        "        segments, segments_copy, translated_lines, target, source\n",
        "    )\n",
        "def fix_code_language(translate_to, syntax=\"google\"):\n",
        "    if syntax == \"google\":\n",
        "        # google-translator, gTTS\n",
        "        replace_lang_code = {\"zh\": \"zh-CN\", \"he\": \"iw\", \"zh-cn\": \"zh-CN\"}\n",
        "    elif syntax == \"coqui\":\n",
        "        # coqui-xtts\n",
        "        replace_lang_code = {\"zh\": \"zh-cn\", \"zh-CN\": \"zh-cn\", \"zh-TW\": \"zh-cn\"}\n",
        "\n",
        "    new_code_lang = replace_lang_code.get(translate_to, translate_to)\n",
        "    print(f\"Fix code {translate_to} -> {new_code_lang}\")\n",
        "    return new_code_lang\n",
        "\n",
        "def translate_text(\n",
        "    segments,\n",
        "    target,\n",
        "    translation_process=\"google_translator_batch\",\n",
        "    chunk_size=4500,\n",
        "    source=None,\n",
        "    token_batch_limit=1000,\n",
        "):\n",
        "    \"\"\"Translates text segments using a specified process.\"\"\"\n",
        "    match translation_process:\n",
        "        case \"google_translator_batch\":\n",
        "            return translate_batch(\n",
        "                segments,\n",
        "                fix_code_language(target),\n",
        "                chunk_size,\n",
        "                fix_code_language(source)\n",
        "            )\n",
        "        case \"google_translator\":\n",
        "            return translate_iterative(\n",
        "                segments,\n",
        "                fix_code_language(target),\n",
        "                fix_code_language(source)\n",
        "            )\n",
        "\n",
        "def translate_whisper_text(result,source_lang,destination_lang):\n",
        "  copy_result = copy.deepcopy(result)\n",
        "  translate_process=\"google_translator\"\n",
        "  lang_source=source_lang\n",
        "  TRANSLATE_AUDIO_TO=destination_lang\n",
        "  copy_result['segments']=translate_text(copy_result[\"segments\"],TRANSLATE_AUDIO_TO,translate_process,chunk_size=1800)\n",
        "  return copy_result\n",
        "\n",
        "\n",
        "\n",
        "#@title import CosyVoice model\n",
        "%cd /content/CosyVoice\n",
        "from cosyvoice.cli.cosyvoice import CosyVoice\n",
        "from cosyvoice.utils.file_utils import load_wav\n",
        "import torchaudio\n",
        "cosyvoice=None\n",
        "\n",
        "# cosyvoice = CosyVoice('/content/CosyVoice/pretrained_models/CosyVoice-300M')\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "#@title utils\n",
        "import librosa\n",
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import uuid\n",
        "import torch\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from IPython.display import Audio\n",
        "from IPython.core.display import display\n",
        "from tqdm.notebook import tqdm\n",
        "whisper_model=None\n",
        "select_model =\"tiny\" # ['tiny', 'base']\n",
        "# whisper_model = whisper.load_model(select_model)\n",
        "language_dict = {\n",
        "    \"Chinese\": \"zh\",\n",
        "    \"English\": \"en\",\n",
        "    \"Japanese\": \"ja\",\n",
        "    \"Cantonese\": \"yue\",\n",
        "    \"Korean\": \"ko\"\n",
        "}\n",
        "def convert_to_wav(file_path):\n",
        "    # Check if the file is already a WAV file\n",
        "    if file_path.lower().endswith('.wav'):\n",
        "        # print(f\"{file_path} is already a WAV file.\")\n",
        "        return file_path\n",
        "\n",
        "    # Define the output file path with .wav extension\n",
        "    output_file_path = os.path.splitext(file_path)[0] + '.wav'\n",
        "\n",
        "    # Convert the file to WAV format\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    audio.export(output_file_path, format='wav')\n",
        "    # print(f\"Converted {file_path} to {output_file_path}.\")\n",
        "\n",
        "    return output_file_path\n",
        "\n",
        "def set_all_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def postprocess(wav_file_path, Language,audio_to_text=False,top_db=60, hop_length=220, win_length=440):\n",
        "    global language_dict,whisper_model\n",
        "\n",
        "    max_val = 0.8\n",
        "    prompt_sr, target_sr = 16000, 22050\n",
        "    default_data = np.zeros(target_sr)\n",
        "    if torchaudio.info(wav_file_path).sample_rate < prompt_sr:\n",
        "      prompt_sr=target_sr\n",
        "    speech=load_wav(wav_file_path, prompt_sr)\n",
        "    speech, _ = librosa.effects.trim(\n",
        "        speech, top_db=top_db,\n",
        "        frame_length=win_length,\n",
        "        hop_length=hop_length\n",
        "    )\n",
        "    if speech.abs().max() > max_val:\n",
        "        speech = speech / speech.abs().max() * max_val\n",
        "    speech = torch.concat([speech, torch.zeros(1, int(target_sr * 0.2))], dim=1)\n",
        "    #extract text\n",
        "    if audio_to_text:\n",
        "      result = whisper_model.transcribe(wav_file_path,language=language_dict[Language])\n",
        "      prompt_text=result[\"text\"].strip()\n",
        "    else:\n",
        "      prompt_text=\"\"\n",
        "    # print(f\"Reference Audio Text:\\n{prompt_text}\")\n",
        "    return speech,prompt_text\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def merge_audio(audio_chunks_list, save_path):\n",
        "    # Initialize an empty AudioSegment object for the final output\n",
        "    merged_audio = AudioSegment.empty()\n",
        "\n",
        "    # Loop through the list of audio file paths\n",
        "    for audio_path in audio_chunks_list:\n",
        "        # Load each audio file\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        # Append the audio to the merged_audio object\n",
        "        merged_audio += audio\n",
        "\n",
        "    # Export the merged audio to the specified path in WAV format\n",
        "    merged_audio.export(save_path, format=\"wav\")\n",
        "\n",
        "\n",
        "def chunks_sentences(paragraph, join_limit=2):\n",
        "    sentences = sent_tokenize(paragraph)\n",
        "    # Initialize an empty list to store the new sentences\n",
        "    new_sentences = []\n",
        "\n",
        "    # Iterate through the list of sentences in steps of 'join_limit'\n",
        "    for i in range(0, len(sentences), join_limit):\n",
        "        # Join the sentences with a space between them\n",
        "        new_sentence = ' '.join(sentences[i:i + join_limit])\n",
        "        new_sentences.append(new_sentence)\n",
        "\n",
        "    return new_sentences\n",
        "\n",
        "def speed_change(clone_voice_save_path,speedup_factor):\n",
        "  speedup_filename=clone_voice_save_path.replace(\".wav\",\"_speed_up.wav\")\n",
        "  speed_change_command=f\"ffmpeg -i {clone_voice_save_path} -filter:a atempo={speedup_factor} {speedup_filename} -y\"\n",
        "  var=os.system(speed_change_command)\n",
        "  if var==0:\n",
        "    return speedup_filename\n",
        "  else:\n",
        "    print(speed_change_command)\n",
        "    return None\n",
        "\n",
        "\n",
        "def voice_clone(text,reference_audio_file,Language=\"English\",clone_method=\"3s Quick Clone\",seed=0,save_folder=\".\"):\n",
        "  global language_dict,cosyvoice\n",
        "  if save_folder.endswith(\"/\"):\n",
        "    save_folder=save_folder[:-1]\n",
        "  if not os.path.exists(save_folder):\n",
        "    os.mkdir(save_folder)\n",
        "  small_sentences=chunks_sentences(text)\n",
        "  #may be I am wrong\n",
        "  seed=seed+len(small_sentences)\n",
        "  set_all_random_seed(seed)\n",
        "  wav_file_path=convert_to_wav(reference_audio_file)\n",
        "\n",
        "\n",
        "  if 'COLAB_GPU' in os.environ:\n",
        "    tts_save_folder=\"/content/cosy_tts\"\n",
        "  else:\n",
        "    tts_save_folder=\"./cosy_tts\"\n",
        "  if os.path.exists(tts_save_folder):\n",
        "    shutil.rmtree(tts_save_folder)\n",
        "  os.mkdir(tts_save_folder)\n",
        "  if clone_method==\"3s Quick Clone\":\n",
        "    prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=True)\n",
        "    print(f\"Reference Audio Text:\\n{prompt_text}\")\n",
        "  else:\n",
        "    prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=False)\n",
        "  audio_chunks_list=[]\n",
        "  for index, tts_text in tqdm(enumerate(small_sentences), total=len(small_sentences)):\n",
        "  # for index, tts_text in enumerate(small_sentences):\n",
        "    if clone_method==\"3s Quick Clone\":\n",
        "      output = cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_speech_16k)\n",
        "    else:\n",
        "      tts_text=f\"<|{language_dict['English']}|> {tts_text}\"\n",
        "      output = cosyvoice.inference_cross_lingual(tts_text, prompt_speech_16k)\n",
        "    temp_file_path=f\"{tts_save_folder}/{index}.wav\"\n",
        "    torchaudio.save(temp_file_path, output['tts_speech'], 22050)\n",
        "    audio_chunks_list.append(temp_file_path)\n",
        "  file_name=text[:20].replace(\" \",\"_\")\n",
        "  file_name=file_name.replace(\"<|\",\"\").replace(\"|>\",\"\")\n",
        "  random_uuid = str(uuid.uuid4())[:6]\n",
        "  save_clone_voice_path=f\"{save_folder}/{file_name}_{random_uuid}.wav\"\n",
        "  if len(audio_chunks_list)==0:\n",
        "    return None\n",
        "  elif len(audio_chunks_list)==1:\n",
        "    shutil.copy(audio_chunks_list[-1],save_clone_voice_path)\n",
        "    return save_clone_voice_path\n",
        "  else:\n",
        "    merge_audio(audio_chunks_list, save_clone_voice_path)\n",
        "    return save_clone_voice_path\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "\n",
        "#@title downloda model\n",
        "cosyvoice = CosyVoice('/content/CosyVoice/pretrained_models/CosyVoice-300M')\n",
        "whisper_model = whisper.load_model(select_model)\n",
        "audio_file_path = \"/content/temp.wav\"\n",
        "Destination_Language = \"English\"\n",
        "Source_Language='English'\n",
        "original_srt,original_word_level_srt,translated_srt=gradio_whisper_subtitle(audio_file_path,Source_Language,Destination_Language)\n",
        "text=\"hi how are you\"\n",
        "Reference_Audio_File=\"/content/temp.wav\"\n",
        "Language = \"English\"\n",
        "Clone_Method = \"3s Quick Clone\"\n",
        "Seed=100\n",
        "save_folder=\"/content/clone_voice\"\n",
        "clone_voice_save_path=voice_clone(text,Reference_Audio_File,Language,Clone_Method,Seed,save_folder)\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "#@title Comment\n",
        "# text=\"Sometimes the stories that don't matter are the ones that matter the most.\"# @param {type: \"string\"}\n",
        "# Reference_Audio_File=\"/content/server_error.wav\"# @param {type: \"string\"}\n",
        "# Language = \"English\" # @param [ 'English','Chinese', 'Japanese', 'Cantonese', 'Korean'] {allow-input: true}\n",
        "# Clone_Method = \"3s Quick Clone\" # @param [\"3s Quick Clone\", \"Cross-lingual Clone\"] {allow-input: true}\n",
        "\n",
        "# Seed=100 # @param {type: \"number\"}\n",
        "# # save_folder=\"/content/clone_voice\" # @param {type: \"string\"}\n",
        "# save_folder=\"/content/clone_voice\"\n",
        "# clone_voice_save_path=voice_clone(text,Reference_Audio_File,Language,Clone_Method,Seed,save_folder)\n",
        "#@title Generate SRT\n",
        "# audio_file_path = '/content/c.wav'  # @param {type: \"string\"}\n",
        "# # Source_Language = \"English\" # @param ['None','English','Hindi','Bengali','Afrikaans', 'Amharic', 'Arabic', 'Azerbaijani', 'Bulgarian', 'Bengali', 'Bosnian', 'Catalan', 'Czech', 'Welsh', 'Danish', 'German', 'Greek', 'English', 'Spanish', 'French', 'Irish', 'Galician', 'Gujarati', 'Hebrew', 'Hindi', 'Croatian', 'Hungarian', 'Indonesian', 'Icelandic', 'Italian', 'Japanese', 'Javanese', 'Georgian', 'Kazakh', 'Khmer', 'Kannada', 'Korean', 'Lao', 'Lithuanian', 'Latvian', 'Macedonian', 'Malayalam', 'Mongolian', 'Marathi', 'Malay', 'Maltese', 'Burmese', 'Norwegian Bokmål', 'Nepali', 'Dutch', 'Polish', 'Pashto', 'Portuguese', 'Romanian', 'Russian', 'Sinhala', 'Slovak', 'Slovenian', 'Somali', 'Albanian', 'Serbian', 'Sundanese', 'Swedish', 'Swahili', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Uzbek', 'Vietnamese', 'Chinese', 'Zulu']\n",
        "# # Destination_Language = \"English\" # @param ['English','Hindi','Bengali','Afrikaans', 'Amharic', 'Arabic', 'Azerbaijani', 'Bulgarian', 'Bengali', 'Bosnian', 'Catalan', 'Czech', 'Welsh', 'Danish', 'German', 'Greek', 'English', 'Spanish', 'French', 'Irish', 'Galician', 'Gujarati', 'Hebrew', 'Hindi', 'Croatian', 'Hungarian', 'Indonesian', 'Icelandic', 'Italian', 'Japanese', 'Javanese', 'Georgian', 'Kazakh', 'Khmer', 'Kannada', 'Korean', 'Lao', 'Lithuanian', 'Latvian', 'Macedonian', 'Malayalam', 'Mongolian', 'Marathi', 'Malay', 'Maltese', 'Burmese', 'Norwegian Bokmål', 'Nepali', 'Dutch', 'Polish', 'Pashto', 'Portuguese', 'Romanian', 'Russian', 'Sinhala', 'Slovak', 'Slovenian', 'Somali', 'Albanian', 'Serbian', 'Sundanese', 'Swedish', 'Swahili', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Uzbek', 'Vietnamese', 'Chinese', 'Zulu']\n",
        "# Source_Language = \"English\"\n",
        "# Destination_Language = \"English\"\n",
        "# original_srt,original_word_level_srt,translated_srt=gradio_whisper_subtitle(audio_file_path,Source_Language,Destination_Language)\n",
        "# from IPython.display import clear_output\n",
        "# clear_output()\n",
        "# from google.colab import files\n",
        "# files.download(original_srt)\n",
        "\n",
        "#@title CosyVoice Funtion for subtitle dubbing\n",
        "# temp_path=voice_clone_for_subtitle(text,prompt_speech_16k,prompt_text,Language,\"3s Quick Clone\",Seed,\"/content/clone_voice\")\n",
        "def voice_clone_for_subtitle(text,prompt_speech_16k,prompt_text,Language=\"English\",clone_method=\"3s Quick Clone\",seed=0,save_folder=\".\"):\n",
        "  global language_dict\n",
        "  if save_folder.endswith(\"/\"):\n",
        "    save_folder=save_folder[:-1]\n",
        "  if not os.path.exists(save_folder):\n",
        "    os.mkdir(save_folder)\n",
        "  small_sentences=chunks_sentences(text)\n",
        "  #may be I am wrong\n",
        "  seed=seed+len(small_sentences)\n",
        "  set_all_random_seed(seed)\n",
        "  if 'COLAB_GPU' in os.environ:\n",
        "    tts_save_folder=\"/content/cosy_tts\"\n",
        "  else:\n",
        "    tts_save_folder=\"./cosy_tts\"\n",
        "  if os.path.exists(tts_save_folder):\n",
        "    shutil.rmtree(tts_save_folder)\n",
        "  os.mkdir(tts_save_folder)\n",
        "  audio_chunks_list=[]\n",
        "  # for index, tts_text in tqdm(enumerate(small_sentences), total=len(small_sentences)):\n",
        "  for index, tts_text in enumerate(small_sentences):\n",
        "    if clone_method==\"3s Quick Clone\":\n",
        "      output = cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_speech_16k)\n",
        "    else:\n",
        "      tts_text=f\"<|{language_dict['English']}|> {tts_text}\"\n",
        "      output = cosyvoice.inference_cross_lingual(tts_text, prompt_speech_16k)\n",
        "    temp_file_path=f\"{tts_save_folder}/{index}.wav\"\n",
        "    torchaudio.save(temp_file_path, output['tts_speech'], 22050)\n",
        "    audio_chunks_list.append(temp_file_path)\n",
        "  file_name=text[:20].replace(\" \",\"_\")\n",
        "  file_name=file_name.replace(\"<|\",\"\").replace(\"|>\",\"\")\n",
        "  bad_list=[\"/\",\".\",\"'\",'\"']\n",
        "  for i in bad_list:\n",
        "    file_name=file_name.replace(i,\"\")\n",
        "  random_uuid = str(uuid.uuid4())[:6]\n",
        "  save_clone_voice_path=f\"{save_folder}/{file_name}_{random_uuid}.wav\"\n",
        "  if len(audio_chunks_list)==0:\n",
        "    return None\n",
        "  elif len(audio_chunks_list)==1:\n",
        "    shutil.copy(audio_chunks_list[-1],save_clone_voice_path)\n",
        "    return save_clone_voice_path\n",
        "  else:\n",
        "    merge_audio(audio_chunks_list, save_clone_voice_path)\n",
        "    return save_clone_voice_path\n",
        "\n",
        "def your_tts(text,audio_path,language):\n",
        "  global Reference_Audio_File,Language,Clone_Method,Seed\n",
        "  wav_file_path=convert_to_wav(Reference_Audio_File)\n",
        "  if Clone_Method==\"3s Quick Clone\":\n",
        "    prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=True)\n",
        "  else:\n",
        "    prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=False)\n",
        "  temp_path=voice_clone_for_subtitle(text,prompt_speech_16k,prompt_text,Language,\"3s Quick Clone\",Seed,\"/content/clone_voice\")\n",
        "  shutil.copy(temp_path,audio_path)\n",
        "\n",
        "\n",
        "#@title Generate Audio File From Subtitle\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "def get_subtitle_Dub_path(srt_file_path,Language):\n",
        "  file_name = os.path.splitext(os.path.basename(srt_file_path))[0]\n",
        "  if not os.path.exists(\"/content/TTS_DUB\"):\n",
        "    os.mkdir(\"/content/TTS_DUB\")\n",
        "  new_path=f\"/content/TTS_DUB/{Language}_{file_name}.wav\"\n",
        "  return new_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "def get_video_duration(video_path):\n",
        "    try:\n",
        "        # Run ffmpeg command to get video information in JSON format\n",
        "        result = subprocess.run(\n",
        "            ['ffmpeg', '-i', video_path, '-f', 'ffmetadata', '-'],\n",
        "            stderr=subprocess.PIPE,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        # Parse the duration from the stderr output\n",
        "        for line in result.stderr.split('\\n'):\n",
        "            if 'Duration' in line:\n",
        "                duration_str = line.split('Duration: ')[1].split(',')[0]\n",
        "                h, m, s = duration_str.split(':')\n",
        "                duration = int(h) * 3600 + int(m) * 60 + float(s)\n",
        "                return duration\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def replace_audio(video_path,audio_path):\n",
        "  if not video_path.lower().endswith(\".mp4\"):\n",
        "    return\n",
        "  tts_audio = AudioSegment.from_file(dub_save_path)\n",
        "  audio_duration = len(tts_audio)/1000\n",
        "  video_duration=get_video_duration(video_path)\n",
        "  slience_duration=video_duration-audio_duration\n",
        "  audio_segment = AudioSegment.from_file(audio_path)\n",
        "  slience_Segment= AudioSegment.silent(duration=slience_duration)\n",
        "  marge_audio=audio_segment+slience_Segment\n",
        "  marge_audio.export(\"/content/new_audio.wav\", format=\"wav\")\n",
        "  command=f\"ffmpeg -i {video_path}  -i /content/new_audio.wav -map 0:v -map 1:a -c:v copy -shortest /content/output.mp4 -y\"\n",
        "  var=os.system(command)\n",
        "  if var==0:\n",
        "    if os.path.exists(\"/content/gdrive/MyDrive/upload\"):\n",
        "      file_name = os.path.basename(video_path)\n",
        "      shutil.copy(\"/content/output.mp4\", f\"/content/gdrive/MyDrive/upload/change_audio_{file_name}\")\n",
        "      print(f\"Copied at drive '/content/gdrive/MyDrive/upload/change_audio_{file_name}'\")\n",
        "      return f\"/content/gdrive/MyDrive/upload/change_audio_{file_name}\"\n",
        "  else:\n",
        "    print(command)\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pysrt\n",
        "\n",
        "def clean_srt(input_path):\n",
        "    file_name = os.path.basename(input_path)\n",
        "    output_folder = \"/content/save_srt\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.mkdir(output_folder)\n",
        "    output_path = f\"{output_folder}/{file_name}\"\n",
        "\n",
        "    def clean_srt_line(text):\n",
        "        bad_list = [\"[\", \"]\", \"♫\", \"\\n\"]\n",
        "        for i in bad_list:\n",
        "            text = text.replace(i, \"\")\n",
        "        return text.strip()\n",
        "\n",
        "    # Load the subtitle file\n",
        "    subs = pysrt.open(input_path)\n",
        "\n",
        "    # Iterate through each subtitle and print its details\n",
        "    with open(output_path, \"w\", encoding='utf-8') as file:\n",
        "        for sub in subs:\n",
        "            file.write(f\"{sub.index}\\n\")\n",
        "            file.write(f\"{sub.start} --> {sub.end}\\n\")\n",
        "            file.write(f\"{clean_srt_line(sub.text)}\\n\")\n",
        "            file.write(\"\\n\")\n",
        "        file.close()\n",
        "    # print(f\"Clean SRT saved at: {output_path}\")\n",
        "    return output_path\n",
        "# Example usage\n",
        "\n",
        "\n",
        "\n",
        "###\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import shutil\n",
        "import subprocess\n",
        "import os\n",
        "import uuid\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# dub_save_path=get_subtitle_Dub_path(srt_file_path,Language)\n",
        "import time\n",
        "\n",
        "# def your_tts(text,audio_path,language):\n",
        "#   global Reference_Audio_File,Language,Clone_Method,Seed\n",
        "#   wav_file_path=convert_to_wav(Reference_Audio_File)\n",
        "#   if Clone_Method==\"3s Quick Clone\":\n",
        "#     prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=True)\n",
        "#   else:\n",
        "#     prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=False)\n",
        "#   temp_path=voice_clone_for_subtitle(text,prompt_speech_16k,prompt_text,Language,\"3s Quick Clone\",Seed,\"/content/clone_voice\")\n",
        "#   shutil.copy(temp_path,audio_path)\n",
        "\n",
        "class SRTDubbing:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def text_to_speech(text, audio_path, language, actual_duration):\n",
        "        tts_filename = \"temp.wav\"\n",
        "        your_tts(text,tts_filename,language)\n",
        "        # Check the duration of the generated TTS audio\n",
        "        tts_audio = AudioSegment.from_file(tts_filename)\n",
        "        tts_duration = len(tts_audio)\n",
        "\n",
        "        if actual_duration == 0:\n",
        "            # If actual duration is zero, use the original TTS audio without modifications\n",
        "            shutil.move(tts_filename, audio_path)\n",
        "            return\n",
        "\n",
        "        # If TTS audio duration is longer than actual duration, speed up the audio\n",
        "        if tts_duration > actual_duration:\n",
        "            speedup_factor = tts_duration / actual_duration\n",
        "            speedup_filename = \"speedup_temp.wav\"\n",
        "\n",
        "            # Use ffmpeg to change audio speed\n",
        "            subprocess.run([\n",
        "                \"ffmpeg\",\n",
        "                \"-i\", tts_filename,\n",
        "                \"-filter:a\", f\"atempo={speedup_factor}\",\n",
        "                speedup_filename\n",
        "            ], check=True)\n",
        "\n",
        "            # Replace the original TTS audio with the sped-up version\n",
        "            shutil.move(speedup_filename, audio_path)\n",
        "        elif tts_duration < actual_duration:\n",
        "            # If TTS audio duration is less than actual duration, add silence to match the duration\n",
        "            silence_gap = actual_duration - tts_duration\n",
        "            silence = AudioSegment.silent(duration=int(silence_gap))\n",
        "            new_audio = tts_audio + silence\n",
        "\n",
        "            # Save the new audio with added silence\n",
        "            new_audio.export(audio_path, format=\"wav\")\n",
        "        else:\n",
        "            # If TTS audio duration is equal to actual duration, use the original TTS audio\n",
        "            shutil.move(tts_filename, audio_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_silence(pause_time, pause_save_path):\n",
        "        silence = AudioSegment.silent(duration=pause_time)\n",
        "        silence.export(pause_save_path, format=\"wav\")\n",
        "        return pause_save_path\n",
        "\n",
        "    @staticmethod\n",
        "    def create_folder_for_srt(srt_file_path):\n",
        "        srt_base_name = os.path.splitext(os.path.basename(srt_file_path))[0]\n",
        "        random_uuid = str(uuid.uuid4())[:4]\n",
        "        dummy_folder_path = \"/content/dummy\"\n",
        "        if not os.path.exists(dummy_folder_path):\n",
        "            os.makedirs(dummy_folder_path)\n",
        "        folder_path = os.path.join(dummy_folder_path, f\"{srt_base_name}_{random_uuid}\")\n",
        "        os.makedirs(folder_path, exist_ok=True)\n",
        "        return folder_path\n",
        "\n",
        "    @staticmethod\n",
        "    def concatenate_audio_files(audio_paths, output_path):\n",
        "        concatenated_audio = AudioSegment.silent(duration=0)\n",
        "        for audio_path in audio_paths:\n",
        "            audio_segment = AudioSegment.from_file(audio_path)\n",
        "            concatenated_audio += audio_segment\n",
        "        concatenated_audio.export(output_path, format=\"wav\")\n",
        "\n",
        "    def srt_to_dub(self, srt_file_path, dub_save_path,language='en'):\n",
        "        result = self.read_srt_file(srt_file_path)\n",
        "        new_folder_path = self.create_folder_for_srt(srt_file_path)\n",
        "        join_path = []\n",
        "        for i in tqdm(result):\n",
        "        # for i in result:\n",
        "            text = i['text']\n",
        "            actual_duration = i['end_time'] - i['start_time']\n",
        "            pause_time = i['pause_time']\n",
        "            slient_path = f\"{new_folder_path}/{i['previous_pause']}\"\n",
        "            self.make_silence(pause_time, slient_path)\n",
        "            join_path.append(slient_path)\n",
        "            tts_path = f\"{new_folder_path}/{i['audio_name']}\"\n",
        "            self.text_to_speech(text, tts_path, language, actual_duration)\n",
        "            join_path.append(tts_path)\n",
        "        self.concatenate_audio_files(join_path, dub_save_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_to_millisecond(time_str):\n",
        "      if isinstance(time_str, str):\n",
        "          hours, minutes, second_millisecond = time_str.split(':')\n",
        "          seconds, milliseconds = second_millisecond.split(\",\")\n",
        "\n",
        "          total_milliseconds = (\n",
        "              int(hours) * 3600000 +\n",
        "              int(minutes) * 60000 +\n",
        "              int(seconds) * 1000 +\n",
        "              int(milliseconds)\n",
        "          )\n",
        "\n",
        "          return total_milliseconds\n",
        "    @staticmethod\n",
        "    def read_srt_file(file_path):\n",
        "        entries = []\n",
        "        default_start = 0\n",
        "        previous_end_time = default_start\n",
        "        entry_number = 1\n",
        "        audio_name_template = \"{}.wav\"\n",
        "        previous_pause_template = \"{}_before_pause.wav\"\n",
        "\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            lines = file.readlines()\n",
        "            # print(lines)\n",
        "            for i in range(0, len(lines), 4):\n",
        "                time_info = re.findall(r'(\\d+:\\d+:\\d+,\\d+) --> (\\d+:\\d+:\\d+,\\d+)', lines[i + 1])\n",
        "                start_time = SRTDubbing.convert_to_millisecond(time_info[0][0])\n",
        "                end_time = SRTDubbing.convert_to_millisecond(time_info[0][1])\n",
        "\n",
        "                current_entry = {\n",
        "                    'entry_number': entry_number,\n",
        "                    'start_time': start_time,\n",
        "                    'end_time': end_time,\n",
        "                    'text': lines[i + 2].strip(),\n",
        "                    'pause_time': start_time - previous_end_time if entry_number != 1 else start_time - default_start,\n",
        "                    'audio_name': audio_name_template.format(entry_number),\n",
        "                    'previous_pause': previous_pause_template.format(entry_number),\n",
        "                }\n",
        "\n",
        "                entries.append(current_entry)\n",
        "                previous_end_time = end_time\n",
        "                entry_number += 1\n",
        "\n",
        "        return entries\n",
        "\n",
        "# # Example usage\n",
        "# Enter_srt_file_path = '/content/subtitle/Original_en_c_2dc46b.srt'  # @param {type: \"string\"}\n",
        "# srt_file_path=clean_srt(Enter_srt_file_path)\n",
        "\n",
        "# Reference_Audio_File=\"/content/c.wav\"# @param {type: \"string\"}\n",
        "# Language = \"English\" # @param [ 'English','Chinese', 'Japanese', 'Cantonese', 'Korean'] {allow-input: true}\n",
        "# Clone_Method = \"3s Quick Clone\" # @param [\"3s Quick Clone\", \"Cross-lingual Clone\"] {allow-input: true}\n",
        "# Seed=100000 # @param {type: \"number\"}\n",
        "\n",
        "\n",
        "# srt_dubbing = SRTDubbing()\n",
        "# current_language=Language\n",
        "# dub_save_path=get_subtitle_Dub_path(srt_file_path,Language)\n",
        "# srt_dubbing.srt_to_dub(srt_file_path, dub_save_path,current_language)\n",
        "# from IPython.display import clear_output\n",
        "# clear_output()\n",
        "# print(f\"{Language} Dub Audio File Save At : {dub_save_path}\")\n",
        "# if os.path.exists(\"/content/gdrive/MyDrive/upload\"):\n",
        "#   file_name = os.path.basename(dub_save_path)\n",
        "#   shutil.copy(dub_save_path, f\"/content/gdrive/MyDrive/upload/{file_name}\")\n",
        "#   print(f\"Copied at drive '/content/gdrive/MyDrive/upload/{file_name}'\")\n",
        "\n",
        "\n",
        "# # replace_audio_path=replace_audio(audio_file_path,dub_save_path)\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "# files.download(dub_save_path)\n",
        "# # files.download(replace_audio_path)\n",
        "\n",
        "#@title main function\n",
        "# Example usage\n",
        "def audio_to_audio(Your_Voice_File,Reference_Audio_File,Clone_Method):\n",
        "  global cosyvoice,whisper_model\n",
        "\n",
        "  try:\n",
        "    if cosyvoice is not None:\n",
        "      del cosyvoice\n",
        "      cosyvoice=None\n",
        "    if whisper_model is not None:\n",
        "      del whisper_model\n",
        "      whisper_model=None\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Free GPU memeory\")\n",
        "  except:\n",
        "    pass\n",
        "  cosyvoice = CosyVoice('/content/CosyVoice/pretrained_models/CosyVoice-300M')\n",
        "  whisper_model = whisper.load_model(select_model)\n",
        "  Source_Language = \"English\"\n",
        "  Destination_Language = \"English\"\n",
        "  original_srt,original_word_level_srt,translated_srt=gradio_whisper_subtitle(Your_Voice_File,Source_Language,Destination_Language)\n",
        "\n",
        "  Enter_srt_file_path =original_srt\n",
        "  srt_file_path=clean_srt(Enter_srt_file_path)\n",
        "\n",
        "  Language = \"English\"\n",
        "  Seed=100000\n",
        "\n",
        "\n",
        "  srt_dubbing = SRTDubbing()\n",
        "  current_language=Language\n",
        "  dub_save_path=get_subtitle_Dub_path(srt_file_path,Language)\n",
        "  srt_dubbing.srt_to_dub(srt_file_path, dub_save_path,current_language)\n",
        "  from IPython.display import clear_output\n",
        "  clear_output()\n",
        "  print(f\"{Language} Dub Audio File Save At : {dub_save_path}\")\n",
        "  if os.path.exists(\"/content/gdrive/MyDrive/upload\"):\n",
        "    file_name = os.path.basename(dub_save_path)\n",
        "    shutil.copy(dub_save_path, f\"/content/gdrive/MyDrive/upload/{file_name}\")\n",
        "    print(f\"Copied at drive '/content/gdrive/MyDrive/upload/{file_name}'\")\n",
        "  return dub_save_path,dub_save_path\n",
        "#@title test\n",
        "# Your_Voice_File= '/content/c.wav'  # @param {type: \"string\"}\n",
        "# Reference_Audio_File=\"/content/c.wav\"# @param {type: \"string\"}\n",
        "# Clone_Method = \"3s Quick Clone\" # @param [\"3s Quick Clone\", \"Cross-lingual Clone\"] {allow-input: true}\n",
        "# dub_save_path,_=audio_to_audio(Your_Voice_File,Reference_Audio_File,Clone_Method)\n",
        "# from IPython.display import clear_output\n",
        "# clear_output()\n",
        "# from google.colab import files\n",
        "# files.download(dub_save_path)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "edZgHWADtz0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Gradio app\n",
        "import gradio as gr\n",
        "demo = gr.Interface(audio_to_audio,\n",
        "                    [gr.Audio(label=\"Your Voice\",type=\"filepath\",sources=['upload', 'microphone']),\n",
        "                     gr.Audio(label=\"Whose voice do you want to clone\",type=\"filepath\",sources=['upload', 'microphone']),\n",
        "                     gr.Dropdown([\"3s Quick Clone\", \"Cross-lingual Clone\"], label=\"Animal\", value=\"3s Quick Clone\"\n",
        "                   )],\n",
        "                    [gr.Audio(label=\"Play Audio\"),gr.File(label=\"Download Audio File\")],\n",
        "                    title=\"Voice Clone\",\n",
        "                    # examples=[['./audio/audio.wav','./audio/audio.wav','3s Quick Clone']],\n",
        "                    cache_examples=True)\n",
        "demo.launch(share=True,debug=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Sg4KEw6RuU_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}