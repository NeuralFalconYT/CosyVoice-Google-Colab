{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a55958e0e83346edb95dd9d2c574d5d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_070f2dbe79c248b9baa069a382126526",
              "IPY_MODEL_ca1b5dc9b4e34395bee9c53ca90d61f9",
              "IPY_MODEL_65b0cdff62af4e799e26d949d2fd2519"
            ],
            "layout": "IPY_MODEL_9c3a3a4129e14e38b793d7f56dea41d0"
          }
        },
        "070f2dbe79c248b9baa069a382126526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1361ef59de1b4039b944f80d5d49a219",
            "placeholder": "​",
            "style": "IPY_MODEL_7380559b626b43629bafe34c1544fe2f",
            "value": " 45%"
          }
        },
        "ca1b5dc9b4e34395bee9c53ca90d61f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d32ff1ef82a4271a35b7079aceba415",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4091e8a383e04331a28aa030d47b85f2",
            "value": 70
          }
        },
        "65b0cdff62af4e799e26d949d2fd2519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2acfb75d3b8437fbfe61a2da30b5c74",
            "placeholder": "​",
            "style": "IPY_MODEL_ca28f9a8685a44e190e14450c91e0974",
            "value": " 70/157 [10:11&lt;12:59,  8.96s/it]"
          }
        },
        "9c3a3a4129e14e38b793d7f56dea41d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1361ef59de1b4039b944f80d5d49a219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7380559b626b43629bafe34c1544fe2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d32ff1ef82a4271a35b7079aceba415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4091e8a383e04331a28aa030d47b85f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2acfb75d3b8437fbfe61a2da30b5c74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca28f9a8685a44e190e14450c91e0974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 🗣🎙️CosyVoice Zero-Shot Voice Cloning 🎙️\n",
        "### Credit\n",
        "[CosyVoice Github](https://github.com/FunAudioLLM/CosyVoice) <br>\n",
        "[Hugging Face Space](https://huggingface.co/spaces/modelscope/CosyVoice-300M) <br>\n",
        "[CosyVoice-300M Model Download](https://www.modelscope.cn/models/iic/CosyVoice-300M)\n",
        "<br>\n",
        "## Disclaimer\n",
        "The content provided below is for academic purposes only and is intended to demonstrate technical capabilities.\n"
      ],
      "metadata": {
        "id": "jXyK8In8Mkx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Automatic Install CosyVoice, Download Model & AUTO-RESTART (Cancel ```Restart session``` Pop UP)\n",
        "import os\n",
        "import shutil\n",
        "!pip install modelscope\n",
        "\n",
        "# root_path=\".\" #for windows/kaggle/mac\n",
        "# root_path=os.getcwd() #else use this one\n",
        "root_path=\"/content\" #if you are not running this on google colab comment this\n",
        "\n",
        "base_path=f\"{root_path}\"\n",
        "os.chdir(base_path)\n",
        "if os.path.exists(f\"{base_path}/CosyVoice\"):\n",
        "  shutil.rmtree(f\"{base_path}/CosyVoice\")\n",
        "  print(f\"Deleting Old {base_path}/CosyVoice\")\n",
        "!git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git\n",
        "os.chdir(f\"{base_path}/CosyVoice\")\n",
        "\n",
        "#Downloading Model using git clone is very slow\n",
        "# !git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M\n",
        "from modelscope import snapshot_download\n",
        "snapshot_download('iic/CosyVoice-300M', local_dir=f'{base_path}/CosyVoice/pretrained_models/CosyVoice-300M')\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install matcha-tts\n",
        "!echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig\n",
        "!pip install pydub==0.25.1\n",
        "!pip install pysrt==1.1.2\n",
        "!pip install librosa==0.10.2.post1\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import time\n",
        "time.sleep(5)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Tbe0ajGk8YVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't panic if Google Colab got disconnected run from the next cell"
      ],
      "metadata": {
        "id": "kywincMsOAPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <-- Tap this if you play on Mobile { display-mode: \"form\" }\n",
        "\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then run the cell below</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "G9TSrudROE2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "8e3d0d62-a0aa-4a53-8c86-61e51c1638df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<b>Press play on the music player to keep the tab alive, then run the cell below</b><br/>\n",
              "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import CosyVoice model\n",
        "%cd /content/CosyVoice\n",
        "from cosyvoice.cli.cosyvoice import CosyVoice\n",
        "from cosyvoice.utils.file_utils import load_wav\n",
        "import torchaudio\n",
        "\n",
        "cosyvoice = CosyVoice('/content/CosyVoice/pretrained_models/CosyVoice-300M')\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "#@title utils\n",
        "import librosa\n",
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import uuid\n",
        "import torch\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from IPython.display import Audio\n",
        "from IPython.core.display import display\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "select_model =\"tiny\" # ['tiny', 'base']\n",
        "whisper_model = whisper.load_model(select_model)\n",
        "language_dict = {\n",
        "    \"Chinese\": \"zh\",\n",
        "    \"English\": \"en\",\n",
        "    \"Japanese\": \"ja\",\n",
        "    \"Cantonese\": \"yue\",\n",
        "    \"Korean\": \"ko\"\n",
        "}\n",
        "def convert_to_wav(file_path):\n",
        "    # Check if the file is already a WAV file\n",
        "    if file_path.lower().endswith('.wav'):\n",
        "        # print(f\"{file_path} is already a WAV file.\")\n",
        "        return file_path\n",
        "\n",
        "    # Define the output file path with .wav extension\n",
        "    output_file_path = os.path.splitext(file_path)[0] + '.wav'\n",
        "\n",
        "    # Convert the file to WAV format\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    audio.export(output_file_path, format='wav')\n",
        "    # print(f\"Converted {file_path} to {output_file_path}.\")\n",
        "\n",
        "    return output_file_path\n",
        "\n",
        "def set_all_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def postprocess(wav_file_path, Language,audio_to_text=False,top_db=60, hop_length=220, win_length=440):\n",
        "    global language_dict\n",
        "    max_val = 0.8\n",
        "    prompt_sr, target_sr = 16000, 22050\n",
        "    default_data = np.zeros(target_sr)\n",
        "    if torchaudio.info(wav_file_path).sample_rate < prompt_sr:\n",
        "      prompt_sr=target_sr\n",
        "    speech=load_wav(wav_file_path, prompt_sr)\n",
        "    speech, _ = librosa.effects.trim(\n",
        "        speech, top_db=top_db,\n",
        "        frame_length=win_length,\n",
        "        hop_length=hop_length\n",
        "    )\n",
        "    if speech.abs().max() > max_val:\n",
        "        speech = speech / speech.abs().max() * max_val\n",
        "    speech = torch.concat([speech, torch.zeros(1, int(target_sr * 0.2))], dim=1)\n",
        "    #extract text\n",
        "    if audio_to_text:\n",
        "      result = whisper_model.transcribe(wav_file_path,language=language_dict[Language])\n",
        "      prompt_text=result[\"text\"].strip()\n",
        "    else:\n",
        "      prompt_text=\"\"\n",
        "    # print(f\"Reference Audio Text:\\n{prompt_text}\")\n",
        "    return speech,prompt_text\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def merge_audio(audio_chunks_list, save_path):\n",
        "    # Initialize an empty AudioSegment object for the final output\n",
        "    merged_audio = AudioSegment.empty()\n",
        "\n",
        "    # Loop through the list of audio file paths\n",
        "    for audio_path in audio_chunks_list:\n",
        "        # Load each audio file\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        # Append the audio to the merged_audio object\n",
        "        merged_audio += audio\n",
        "\n",
        "    # Export the merged audio to the specified path in WAV format\n",
        "    merged_audio.export(save_path, format=\"wav\")\n",
        "\n",
        "\n",
        "def chunks_sentences(paragraph, join_limit=2):\n",
        "    sentences = sent_tokenize(paragraph)\n",
        "    # Initialize an empty list to store the new sentences\n",
        "    new_sentences = []\n",
        "\n",
        "    # Iterate through the list of sentences in steps of 'join_limit'\n",
        "    for i in range(0, len(sentences), join_limit):\n",
        "        # Join the sentences with a space between them\n",
        "        new_sentence = ' '.join(sentences[i:i + join_limit])\n",
        "        new_sentences.append(new_sentence)\n",
        "\n",
        "    return new_sentences\n",
        "\n",
        "def speed_change(clone_voice_save_path,speedup_factor):\n",
        "  speedup_filename=clone_voice_save_path.replace(\".wav\",\"_speed_up.wav\")\n",
        "  speed_change_command=f\"ffmpeg -i {clone_voice_save_path} -filter:a atempo={speedup_factor} {speedup_filename} -y\"\n",
        "  var=os.system(speed_change_command)\n",
        "  if var==0:\n",
        "    return speedup_filename\n",
        "  else:\n",
        "    print(speed_change_command)\n",
        "    return None\n",
        "\n",
        "\n",
        "def voice_clone(text,reference_audio_file,Language=\"English\",clone_method=\"3s Quick Clone\",seed=0,save_folder=\".\"):\n",
        "  global language_dict\n",
        "  if save_folder.endswith(\"/\"):\n",
        "    save_folder=save_folder[:-1]\n",
        "  if not os.path.exists(save_folder):\n",
        "    os.mkdir(save_folder)\n",
        "  small_sentences=chunks_sentences(text)\n",
        "  #may be I am wrong\n",
        "  seed=seed+len(small_sentences)\n",
        "  set_all_random_seed(seed)\n",
        "  wav_file_path=convert_to_wav(reference_audio_file)\n",
        "\n",
        "\n",
        "  if 'COLAB_GPU' in os.environ:\n",
        "    tts_save_folder=\"/content/cosy_tts\"\n",
        "  else:\n",
        "    tts_save_folder=\"./cosy_tts\"\n",
        "  if os.path.exists(tts_save_folder):\n",
        "    shutil.rmtree(tts_save_folder)\n",
        "  os.mkdir(tts_save_folder)\n",
        "  if clone_method==\"3s Quick Clone\":\n",
        "    prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=True)\n",
        "    print(f\"Reference Audio Text:\\n{prompt_text}\")\n",
        "  else:\n",
        "    prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=False)\n",
        "  audio_chunks_list=[]\n",
        "  for index, tts_text in tqdm(enumerate(small_sentences), total=len(small_sentences)):\n",
        "  # for index, tts_text in enumerate(small_sentences):\n",
        "    if clone_method==\"3s Quick Clone\":\n",
        "      output = cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_speech_16k)\n",
        "    else:\n",
        "      tts_text=f\"<|{language_dict['English']}|> {tts_text}\"\n",
        "      output = cosyvoice.inference_cross_lingual(tts_text, prompt_speech_16k)\n",
        "    temp_file_path=f\"{tts_save_folder}/{index}.wav\"\n",
        "    torchaudio.save(temp_file_path, output['tts_speech'], 22050)\n",
        "    audio_chunks_list.append(temp_file_path)\n",
        "  file_name=text[:20].replace(\" \",\"_\")\n",
        "  file_name=file_name.replace(\"<|\",\"\").replace(\"|>\",\"\")\n",
        "  random_uuid = str(uuid.uuid4())[:6]\n",
        "  save_clone_voice_path=f\"{save_folder}/{file_name}_{random_uuid}.wav\"\n",
        "  if len(audio_chunks_list)==0:\n",
        "    return None\n",
        "  elif len(audio_chunks_list)==1:\n",
        "    shutil.copy(audio_chunks_list[-1],save_clone_voice_path)\n",
        "    return save_clone_voice_path\n",
        "  else:\n",
        "    merge_audio(audio_chunks_list, save_clone_voice_path)\n",
        "    return save_clone_voice_path\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gd-iStfn-KfN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Online Audio Cutter](https://mp3cut.net/) &emsp;If you have a larger Audio<br>\n",
        "[Vocal & Music Seperator](https://vocalremover.org/)&emsp;If you have a audio with background Music<br>\n",
        "[Enhance low quality audio](https://podcast.adobe.com/)&emsp;If your audio file have poor audio quality"
      ],
      "metadata": {
        "id": "JT3iSIjTDbNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload 6s Audio clip\n",
        "import os\n",
        "from google.colab import files\n",
        "%cd /content/\n",
        "uploaded = files.upload()\n",
        "%cd /content/CosyVoice/\n",
        "upload_list=[]\n",
        "for fn in uploaded.keys():\n",
        "  upload_list.append('/content/'+fn)\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "upload_list[-1]"
      ],
      "metadata": {
        "id": "0owntuDcYXxf",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9817f31-39a8-4d73-8b07-73012ab358eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/my_voice.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run CosyVoice for voice cloning (Support Long Text)\n",
        "text=\"Sometimes the stories that don't matter are the ones that matter the most.\"# @param {type: \"string\"}\n",
        "Reference_Audio_File=\"/content/my_voice.mp3\"# @param {type: \"string\"}\n",
        "Language = \"English\" # @param [ 'English','Chinese', 'Japanese', 'Cantonese', 'Korean'] {allow-input: true}\n",
        "Clone_Method = \"3s Quick Clone\" # @param [\"3s Quick Clone\", \"Cross-lingual Clone\"] {allow-input: true}\n",
        "\n",
        "Seed=100 # @param {type: \"number\"}\n",
        "# save_folder=\"/content/clone_voice\" # @param {type: \"string\"}\n",
        "save_folder=\"/content/clone_voice\"\n",
        "clone_voice_save_path=voice_clone(text,Reference_Audio_File,Language,Clone_Method,Seed,save_folder)\n"
      ],
      "metadata": {
        "id": "kpvoUpiplGcS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display Original & Cloned Voice\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def audio_duration_check(file_path):\n",
        "    audio = AudioSegment.from_file(file_path)\n",
        "    duration_ms = len(audio)  # Duration in milliseconds\n",
        "    duration_s = duration_ms / 1000  # Convert to seconds\n",
        "    return duration_s <= 240  # 4 minutes in seconds\n",
        "\n",
        "print(f\"Original Audio File:\")\n",
        "if audio_duration_check(Reference_Audio_File):\n",
        "  display(Audio(Reference_Audio_File, autoplay=False))\n",
        "else:\n",
        "  print(\"Audio File is larger please download the audio in your local device\")\n",
        "  print(f\"Save at {Reference_Audio_File}\")\n",
        "\n",
        "print(f\"Cloned Audio File:\")\n",
        "if audio_duration_check(clone_voice_save_path):\n",
        "  display(Audio(clone_voice_save_path, autoplay=False))\n",
        "else:\n",
        "  print(\"Audio File is larger please download the audio in your local device\")\n",
        "  print(f\"Save at {clone_voice_save_path}\")\n",
        "  files.download(clone_voice_save_path)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Sr8uaoNUEvuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Cloned Voice\n",
        "from google.colab import files\n",
        "print(f\"Save at {clone_voice_save_path}\")\n",
        "files.download(clone_voice_save_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "J9zbZgsh-UFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MwYup2w3AFO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Kw8ieI9AEu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Audio Speed"
      ],
      "metadata": {
        "id": "8uOAsmF8LYDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Change the audio speed to achieve your desired voice\n",
        "speed=\"1.2\"  # @param {type: \"string\"}\n",
        "speedup_factor=float(speed)\n",
        "speed_change_file=speed_change(clone_voice_save_path,speedup_factor)\n",
        "\n",
        "print(f\"Cloned Audio File:\")\n",
        "if audio_duration_check(clone_voice_save_path):\n",
        "  display(Audio(clone_voice_save_path, autoplay=False))\n",
        "else:\n",
        "  print(\"Audio File is larger please download the audio in your local device\")\n",
        "  print(f\"Save at {clone_voice_save_path}\")\n",
        "  files.download(clone_voice_save_path)\n",
        "\n",
        "print(f\"Cloned Audio File After Speed Change:\")\n",
        "if audio_duration_check(speed_change_file):\n",
        "  display(Audio(speed_change_file, autoplay=False))\n",
        "else:\n",
        "  print(\"Audio File is larger please download the audio in your local device\")\n",
        "  print(f\"Save at {speed_change_file}\")\n",
        "  files.download(speed_change_file)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kPzHCY3oGILN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the speed-changed cloned voice\n",
        "from google.colab import files\n",
        "print(f\"Save at {clone_voice_save_path}\")\n",
        "files.download(clone_voice_save_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lsH1PGAlIh0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "byQ0jrw0_u7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Use as function\n",
        "\n",
        "# voice_clone(text=\"hi how are you \",reference_audio_file='/content/audio.wav',Language='English',clone_method=\"3s Quick Clone\",seed=0,save_folder=\"/content/clone_voice\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DJKmsIoo9bkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CosyVoice Funtion for subtitle dubbing\n",
        "# temp_path=voice_clone_for_subtitle(text,prompt_speech_16k,prompt_text,Language,\"3s Quick Clone\",Seed,\"/content/clone_voice\")\n",
        "def voice_clone_for_subtitle(text,prompt_speech_16k,prompt_text,Language=\"English\",clone_method=\"3s Quick Clone\",seed=0,save_folder=\".\"):\n",
        "  global language_dict\n",
        "  if save_folder.endswith(\"/\"):\n",
        "    save_folder=save_folder[:-1]\n",
        "  if not os.path.exists(save_folder):\n",
        "    os.mkdir(save_folder)\n",
        "  small_sentences=chunks_sentences(text)\n",
        "  #may be I am wrong\n",
        "  seed=seed+len(small_sentences)\n",
        "  set_all_random_seed(seed)\n",
        "  if 'COLAB_GPU' in os.environ:\n",
        "    tts_save_folder=\"/content/cosy_tts\"\n",
        "  else:\n",
        "    tts_save_folder=\"./cosy_tts\"\n",
        "  if os.path.exists(tts_save_folder):\n",
        "    shutil.rmtree(tts_save_folder)\n",
        "  os.mkdir(tts_save_folder)\n",
        "  audio_chunks_list=[]\n",
        "  # for index, tts_text in tqdm(enumerate(small_sentences), total=len(small_sentences)):\n",
        "  for index, tts_text in enumerate(small_sentences):\n",
        "    if clone_method==\"3s Quick Clone\":\n",
        "      output = cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_speech_16k)\n",
        "    else:\n",
        "      tts_text=f\"<|{language_dict['English']}|> {tts_text}\"\n",
        "      output = cosyvoice.inference_cross_lingual(tts_text, prompt_speech_16k)\n",
        "    temp_file_path=f\"{tts_save_folder}/{index}.wav\"\n",
        "    torchaudio.save(temp_file_path, output['tts_speech'], 22050)\n",
        "    audio_chunks_list.append(temp_file_path)\n",
        "  file_name=text[:20].replace(\" \",\"_\")\n",
        "  file_name=file_name.replace(\"<|\",\"\").replace(\"|>\",\"\")\n",
        "  bad_list=[\"/\",\".\",\"'\",'\"']\n",
        "  for i in bad_list:\n",
        "    file_name=file_name.replace(i,\"\")\n",
        "  random_uuid = str(uuid.uuid4())[:6]\n",
        "  save_clone_voice_path=f\"{save_folder}/{file_name}_{random_uuid}.wav\"\n",
        "  if len(audio_chunks_list)==0:\n",
        "    return None\n",
        "  elif len(audio_chunks_list)==1:\n",
        "    shutil.copy(audio_chunks_list[-1],save_clone_voice_path)\n",
        "    return save_clone_voice_path\n",
        "  else:\n",
        "    merge_audio(audio_chunks_list, save_clone_voice_path)\n",
        "    return save_clone_voice_path\n",
        "\n",
        "def your_tts(text,audio_path,language):\n",
        "  global Reference_Audio_File,Language,Clone_Method,Seed\n",
        "  wav_file_path=convert_to_wav(Reference_Audio_File)\n",
        "  if Clone_Method==\"3s Quick Clone\":\n",
        "    prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=True)\n",
        "  else:\n",
        "    prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=False)\n",
        "  temp_path=voice_clone_for_subtitle(text,prompt_speech_16k,prompt_text,Language,\"3s Quick Clone\",Seed,\"/content/clone_voice\")\n",
        "  shutil.copy(temp_path,audio_path)"
      ],
      "metadata": {
        "id": "jQzM1l4Z_uio",
        "cellView": "form"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subtitle Dubbing (Need update, for now it's very slow)"
      ],
      "metadata": {
        "id": "hQ1U1BUm_vrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive to autosave the generated audio file\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qjd1z-XkEf7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad77a215-fcc1-4f2d-9e16-928418b5471f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload a Subtitle\n",
        "import os\n",
        "from google.colab import files\n",
        "%cd /content/\n",
        "uploaded = files.upload()\n",
        "%cd /content/CosyVoice/\n",
        "upload_list=[]\n",
        "for fn in uploaded.keys():\n",
        "  upload_list.append('/content/'+fn)\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "upload_list[-1]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GRZ5XUnD_hZe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8acd3f29-30ec-485a-cba5-3e24edd54eb1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sub.srt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Audio File From Subtitle\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "def get_subtitle_Dub_path(srt_file_path,Language):\n",
        "  file_name = os.path.splitext(os.path.basename(srt_file_path))[0]\n",
        "  if not os.path.exists(\"/content/TTS_DUB\"):\n",
        "    os.mkdir(\"/content/TTS_DUB\")\n",
        "  new_path=f\"/content/TTS_DUB/{Language}_{file_name}.wav\"\n",
        "  return new_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "def get_video_duration(video_path):\n",
        "    try:\n",
        "        # Run ffmpeg command to get video information in JSON format\n",
        "        result = subprocess.run(\n",
        "            ['ffmpeg', '-i', video_path, '-f', 'ffmetadata', '-'],\n",
        "            stderr=subprocess.PIPE,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        # Parse the duration from the stderr output\n",
        "        for line in result.stderr.split('\\n'):\n",
        "            if 'Duration' in line:\n",
        "                duration_str = line.split('Duration: ')[1].split(',')[0]\n",
        "                h, m, s = duration_str.split(':')\n",
        "                duration = int(h) * 3600 + int(m) * 60 + float(s)\n",
        "                return duration\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def replace_audio(video_path,audio_path):\n",
        "  if not video_path.lower().endswith(\".mp4\"):\n",
        "    return\n",
        "  tts_audio = AudioSegment.from_file(dub_save_path)\n",
        "  audio_duration = len(tts_audio)/1000\n",
        "  video_duration=get_video_duration(video_path)\n",
        "  slience_duration=video_duration-audio_duration\n",
        "  audio_segment = AudioSegment.from_file(audio_path)\n",
        "  slience_Segment= AudioSegment.silent(duration=slience_duration)\n",
        "  marge_audio=audio_segment+slience_Segment\n",
        "  marge_audio.export(\"/content/new_audio.wav\", format=\"wav\")\n",
        "  command=f\"ffmpeg -i {video_path}  -i /content/new_audio.wav -map 0:v -map 1:a -c:v copy -shortest /content/output.mp4 -y\"\n",
        "  var=os.system(command)\n",
        "  if var==0:\n",
        "    if os.path.exists(\"/content/gdrive/MyDrive/upload\"):\n",
        "      file_name = os.path.basename(video_path)\n",
        "      shutil.copy(\"/content/output.mp4\", f\"/content/gdrive/MyDrive/upload/change_audio_{file_name}\")\n",
        "      print(f\"Copied at drive '/content/gdrive/MyDrive/upload/change_audio_{file_name}'\")\n",
        "      return f\"/content/gdrive/MyDrive/upload/change_audio_{file_name}\"\n",
        "  else:\n",
        "    print(command)\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pysrt\n",
        "\n",
        "def clean_srt(input_path):\n",
        "    file_name = os.path.basename(input_path)\n",
        "    output_folder = \"/content/save_srt\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.mkdir(output_folder)\n",
        "    output_path = f\"{output_folder}/{file_name}\"\n",
        "\n",
        "    def clean_srt_line(text):\n",
        "        bad_list = [\"[\", \"]\", \"♫\", \"\\n\"]\n",
        "        for i in bad_list:\n",
        "            text = text.replace(i, \"\")\n",
        "        return text.strip()\n",
        "\n",
        "    # Load the subtitle file\n",
        "    subs = pysrt.open(input_path)\n",
        "\n",
        "    # Iterate through each subtitle and print its details\n",
        "    with open(output_path, \"w\", encoding='utf-8') as file:\n",
        "        for sub in subs:\n",
        "            file.write(f\"{sub.index}\\n\")\n",
        "            file.write(f\"{sub.start} --> {sub.end}\\n\")\n",
        "            file.write(f\"{clean_srt_line(sub.text)}\\n\")\n",
        "            file.write(\"\\n\")\n",
        "        file.close()\n",
        "    # print(f\"Clean SRT saved at: {output_path}\")\n",
        "    return output_path\n",
        "# Example usage\n",
        "\n",
        "\n",
        "\n",
        "###\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import shutil\n",
        "import subprocess\n",
        "import os\n",
        "import uuid\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# dub_save_path=get_subtitle_Dub_path(srt_file_path,Language)\n",
        "import time\n",
        "\n",
        "# def your_tts(text,audio_path,language):\n",
        "#   global Reference_Audio_File,Language,Clone_Method,Seed\n",
        "#   wav_file_path=convert_to_wav(Reference_Audio_File)\n",
        "#   if Clone_Method==\"3s Quick Clone\":\n",
        "#     prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=True)\n",
        "#   else:\n",
        "#     prompt_speech_16k,prompt_text = postprocess(wav_file_path,Language,audio_to_text=False)\n",
        "#   temp_path=voice_clone_for_subtitle(text,prompt_speech_16k,prompt_text,Language,\"3s Quick Clone\",Seed,\"/content/clone_voice\")\n",
        "#   shutil.copy(temp_path,audio_path)\n",
        "\n",
        "class SRTDubbing:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def text_to_speech(text, audio_path, language, actual_duration):\n",
        "        tts_filename = \"temp.wav\"\n",
        "        your_tts(text,tts_filename,language)\n",
        "        # Check the duration of the generated TTS audio\n",
        "        tts_audio = AudioSegment.from_file(tts_filename)\n",
        "        tts_duration = len(tts_audio)\n",
        "\n",
        "        if actual_duration == 0:\n",
        "            # If actual duration is zero, use the original TTS audio without modifications\n",
        "            shutil.move(tts_filename, audio_path)\n",
        "            return\n",
        "\n",
        "        # If TTS audio duration is longer than actual duration, speed up the audio\n",
        "        if tts_duration > actual_duration:\n",
        "            speedup_factor = tts_duration / actual_duration\n",
        "            speedup_filename = \"speedup_temp.wav\"\n",
        "\n",
        "            # Use ffmpeg to change audio speed\n",
        "            subprocess.run([\n",
        "                \"ffmpeg\",\n",
        "                \"-i\", tts_filename,\n",
        "                \"-filter:a\", f\"atempo={speedup_factor}\",\n",
        "                speedup_filename\n",
        "            ], check=True)\n",
        "\n",
        "            # Replace the original TTS audio with the sped-up version\n",
        "            shutil.move(speedup_filename, audio_path)\n",
        "        elif tts_duration < actual_duration:\n",
        "            # If TTS audio duration is less than actual duration, add silence to match the duration\n",
        "            silence_gap = actual_duration - tts_duration\n",
        "            silence = AudioSegment.silent(duration=int(silence_gap))\n",
        "            new_audio = tts_audio + silence\n",
        "\n",
        "            # Save the new audio with added silence\n",
        "            new_audio.export(audio_path, format=\"wav\")\n",
        "        else:\n",
        "            # If TTS audio duration is equal to actual duration, use the original TTS audio\n",
        "            shutil.move(tts_filename, audio_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_silence(pause_time, pause_save_path):\n",
        "        silence = AudioSegment.silent(duration=pause_time)\n",
        "        silence.export(pause_save_path, format=\"wav\")\n",
        "        return pause_save_path\n",
        "\n",
        "    @staticmethod\n",
        "    def create_folder_for_srt(srt_file_path):\n",
        "        srt_base_name = os.path.splitext(os.path.basename(srt_file_path))[0]\n",
        "        random_uuid = str(uuid.uuid4())[:4]\n",
        "        dummy_folder_path = \"/content/dummy\"\n",
        "        if not os.path.exists(dummy_folder_path):\n",
        "            os.makedirs(dummy_folder_path)\n",
        "        folder_path = os.path.join(dummy_folder_path, f\"{srt_base_name}_{random_uuid}\")\n",
        "        os.makedirs(folder_path, exist_ok=True)\n",
        "        return folder_path\n",
        "\n",
        "    @staticmethod\n",
        "    def concatenate_audio_files(audio_paths, output_path):\n",
        "        concatenated_audio = AudioSegment.silent(duration=0)\n",
        "        for audio_path in audio_paths:\n",
        "            audio_segment = AudioSegment.from_file(audio_path)\n",
        "            concatenated_audio += audio_segment\n",
        "        concatenated_audio.export(output_path, format=\"wav\")\n",
        "\n",
        "    def srt_to_dub(self, srt_file_path, dub_save_path,language='en'):\n",
        "        result = self.read_srt_file(srt_file_path)\n",
        "        new_folder_path = self.create_folder_for_srt(srt_file_path)\n",
        "        join_path = []\n",
        "        for i in tqdm(result):\n",
        "        # for i in result:\n",
        "            text = i['text']\n",
        "            actual_duration = i['end_time'] - i['start_time']\n",
        "            pause_time = i['pause_time']\n",
        "            slient_path = f\"{new_folder_path}/{i['previous_pause']}\"\n",
        "            self.make_silence(pause_time, slient_path)\n",
        "            join_path.append(slient_path)\n",
        "            tts_path = f\"{new_folder_path}/{i['audio_name']}\"\n",
        "            self.text_to_speech(text, tts_path, language, actual_duration)\n",
        "            join_path.append(tts_path)\n",
        "        self.concatenate_audio_files(join_path, dub_save_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_to_millisecond(time_str):\n",
        "      if isinstance(time_str, str):\n",
        "          hours, minutes, second_millisecond = time_str.split(':')\n",
        "          seconds, milliseconds = second_millisecond.split(\",\")\n",
        "\n",
        "          total_milliseconds = (\n",
        "              int(hours) * 3600000 +\n",
        "              int(minutes) * 60000 +\n",
        "              int(seconds) * 1000 +\n",
        "              int(milliseconds)\n",
        "          )\n",
        "\n",
        "          return total_milliseconds\n",
        "    @staticmethod\n",
        "    def read_srt_file(file_path):\n",
        "        entries = []\n",
        "        default_start = 0\n",
        "        previous_end_time = default_start\n",
        "        entry_number = 1\n",
        "        audio_name_template = \"{}.wav\"\n",
        "        previous_pause_template = \"{}_before_pause.wav\"\n",
        "\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            lines = file.readlines()\n",
        "            # print(lines)\n",
        "            for i in range(0, len(lines), 4):\n",
        "                time_info = re.findall(r'(\\d+:\\d+:\\d+,\\d+) --> (\\d+:\\d+:\\d+,\\d+)', lines[i + 1])\n",
        "                start_time = SRTDubbing.convert_to_millisecond(time_info[0][0])\n",
        "                end_time = SRTDubbing.convert_to_millisecond(time_info[0][1])\n",
        "\n",
        "                current_entry = {\n",
        "                    'entry_number': entry_number,\n",
        "                    'start_time': start_time,\n",
        "                    'end_time': end_time,\n",
        "                    'text': lines[i + 2].strip(),\n",
        "                    'pause_time': start_time - previous_end_time if entry_number != 1 else start_time - default_start,\n",
        "                    'audio_name': audio_name_template.format(entry_number),\n",
        "                    'previous_pause': previous_pause_template.format(entry_number),\n",
        "                }\n",
        "\n",
        "                entries.append(current_entry)\n",
        "                previous_end_time = end_time\n",
        "                entry_number += 1\n",
        "\n",
        "        return entries\n",
        "\n",
        "# Example usage\n",
        "Enter_srt_file_path = '/content/sub.srt'  # @param {type: \"string\"}\n",
        "srt_file_path=clean_srt(Enter_srt_file_path)\n",
        "\n",
        "Reference_Audio_File=\"/content/my_voice.mp3\"# @param {type: \"string\"}\n",
        "Language = \"English\" # @param [ 'English','Chinese', 'Japanese', 'Cantonese', 'Korean'] {allow-input: true}\n",
        "Clone_Method = \"3s Quick Clone\" # @param [\"3s Quick Clone\", \"Cross-lingual Clone\"] {allow-input: true}\n",
        "Seed=100000 # @param {type: \"number\"}\n",
        "\n",
        "\n",
        "srt_dubbing = SRTDubbing()\n",
        "current_language=Language\n",
        "dub_save_path=get_subtitle_Dub_path(srt_file_path,Language)\n",
        "srt_dubbing.srt_to_dub(srt_file_path, dub_save_path,current_language)\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(f\"{Language} Dub Audio File Save At : {dub_save_path}\")\n",
        "if os.path.exists(\"/content/gdrive/MyDrive/upload\"):\n",
        "  file_name = os.path.basename(dub_save_path)\n",
        "  shutil.copy(dub_save_path, f\"/content/gdrive/MyDrive/upload/{file_name}\")\n",
        "  print(f\"Copied at drive '/content/gdrive/MyDrive/upload/{file_name}'\")\n",
        "\n",
        "\n",
        "# replace_audio_path=replace_audio(audio_file_path,dub_save_path)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(dub_save_path)\n",
        "# files.download(replace_audio_path)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6BRnyfTQ7B7Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a55958e0e83346edb95dd9d2c574d5d7",
            "070f2dbe79c248b9baa069a382126526",
            "ca1b5dc9b4e34395bee9c53ca90d61f9",
            "65b0cdff62af4e799e26d949d2fd2519",
            "9c3a3a4129e14e38b793d7f56dea41d0",
            "1361ef59de1b4039b944f80d5d49a219",
            "7380559b626b43629bafe34c1544fe2f",
            "1d32ff1ef82a4271a35b7079aceba415",
            "4091e8a383e04331a28aa030d47b85f2",
            "e2acfb75d3b8437fbfe61a2da30b5c74",
            "ca28f9a8685a44e190e14450c91e0974"
          ]
        },
        "outputId": "fdf946c4-5110-4ae6-d1a3-0525210e53fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a55958e0e83346edb95dd9d2c574d5d7"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}